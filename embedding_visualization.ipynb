{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W9O7x0jbUiVh"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import BertTokenizerFast, BertForTokenClassification, AdamW\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zFEMoQLWUpIT",
        "outputId": "d709bafe-d0aa-4787-93e3-87617ec18d43"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bqjxD3OqUiVp"
      },
      "outputs": [],
      "source": [
        "# Stałe\n",
        "BATCH_SIZE = 16\n",
        "EPOCHS = 3\n",
        "LEARNING_RATE = 5e-5\n",
        "MAX_LEN = 128\n",
        "TRAIN_SIZE = 0.8\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5VpcUXPKUiVr",
        "outputId": "73c554e8-f6d4-49fb-8461-f04c1e604559"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   sentence_id  word_id        word  Olek  Kuba Zgodne?  Stachu  \\\n",
            "0            1        1          Do     3     3       T     NaN   \n",
            "1            1        2       Bosch     1     1       T     NaN   \n",
            "2            1        3  SMV53L10EU     1     1       T     NaN   \n",
            "3            1        4      pasuje     2     2       T     NaN   \n",
            "4            1        5    IDEALNIE     2     2       T     NaN   \n",
            "\n",
            "   final-annotation  Unnamed: 8  \n",
            "0                 3         NaN  \n",
            "1                 1         NaN  \n",
            "2                 1         NaN  \n",
            "3                 2         NaN  \n",
            "4                 2         NaN  \n"
          ]
        }
      ],
      "source": [
        "# Wczytanie i przygotowanie danych\n",
        "df = pd.read_csv('/content/drive/MyDrive/studia/NLP/NLP-Zad2/data/annotations_all_batches - WORD - SECOND BATCH.csv')\n",
        "print(df.head())\n",
        "df = df.fillna(method='ffill')\n",
        "\n",
        "# Grupowanie po sentence_id\n",
        "sentences = df.groupby('sentence_id').agg({\n",
        "    'word': lambda x: list(x),\n",
        "    'final-annotation': lambda x: list(x)\n",
        "}).reset_index()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install sacremoses"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YBeU9W9CVOrV",
        "outputId": "7fd8c7c7-5a79-4354-ae5a-55ebf1b99b6b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting sacremoses\n",
            "  Downloading sacremoses-0.1.1-py3-none-any.whl.metadata (8.3 kB)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from sacremoses) (2024.9.11)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from sacremoses) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from sacremoses) (1.4.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from sacremoses) (4.66.6)\n",
            "Downloading sacremoses-0.1.1-py3-none-any.whl (897 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/897.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m897.5/897.5 kB\u001b[0m \u001b[31m36.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: sacremoses\n",
            "Successfully installed sacremoses-0.1.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b768b70c",
        "outputId": "84d89127-424f-4b47-ce8c-8a7074f4634e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForTokenClassification were not initialized from the model checkpoint at allegro/herbert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PEFT model is ready!\n",
            "trainable params: 1,179,648 || all params: 125,035,012 || trainable%: 0.9435\n"
          ]
        }
      ],
      "source": [
        "from peft import LoraConfig, get_peft_model\n",
        "from transformers import AutoModelForTokenClassification, AutoTokenizer\n",
        "\n",
        "# Model setup with PEFT\n",
        "model_name = \"allegro/herbert-base-cased\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "base_model = AutoModelForTokenClassification.from_pretrained(model_name, num_labels=4)\n",
        "\n",
        "# Configure LoRA (Low-Rank Adaptation)\n",
        "peft_config = LoraConfig(\n",
        "    r=32,  # Rank\n",
        "    lora_alpha=32,\n",
        "    target_modules=[\"query\", \"value\"],  # Layers to apply LoRA\n",
        "    lora_dropout=0.1,\n",
        "    bias=\"none\"\n",
        ")\n",
        "\n",
        "# Wrap the model with PEFT\n",
        "model = get_peft_model(base_model, peft_config)\n",
        "print(\"PEFT model is ready!\")\n",
        "model.print_trainable_parameters()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import torch\n",
        "# from transformers import AutoModelForTokenClassification, AutoTokenizer\n",
        "# from peft import PeftModel, PeftConfig\n",
        "\n",
        "# peft_model_id = \"/content/drive/MyDrive/studia/NLP/NLP-Zad2/save_model/bert_peft_tokens\"\n",
        "# config = PeftConfig.from_pretrained(peft_model_id)\n",
        "# model = AutoModelForTokenClassification.from_pretrained(config.base_model_name_or_path, num_labels=4)\n",
        "# model = PeftModel.from_pretrained(model, peft_model_id)\n",
        "# tokenizer = AutoTokenizer.from_pretrained(config.base_model_name_or_path)\n",
        "# print(\"Model and tokenizer loaded successfully!\")"
      ],
      "metadata": {
        "id": "iBQESzyfj0Sl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xgI9cR7YUiVt"
      },
      "outputs": [],
      "source": [
        "# Klasa dataset\n",
        "class TokenClassificationDataset(Dataset):\n",
        "    def __init__(self, texts, labels, tokenizer, max_len):\n",
        "        self.texts = texts\n",
        "        self.labels = labels\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_len = max_len\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.texts)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        words = self.texts[idx]\n",
        "        labels = self.labels[idx]\n",
        "\n",
        "        # Tokenizacja\n",
        "        encoding = self.tokenizer(\n",
        "            words,\n",
        "            is_split_into_words=True,\n",
        "            max_length=self.max_len,\n",
        "            padding='max_length',\n",
        "            truncation=True,\n",
        "            return_tensors='pt'\n",
        "        )\n",
        "\n",
        "        # Dostosowanie etykiet do tokenów\n",
        "        word_ids = encoding.word_ids()\n",
        "        label_ids = []\n",
        "\n",
        "        for word_id in word_ids:\n",
        "            if word_id is None:\n",
        "                label_ids.append(-100)\n",
        "            else:\n",
        "                label_ids.append(labels[word_id])\n",
        "\n",
        "        return {\n",
        "            'input_ids': encoding['input_ids'].flatten(),\n",
        "            'attention_mask': encoding['attention_mask'].flatten(),\n",
        "            'labels': torch.tensor(label_ids)\n",
        "        }\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tbkf_zZgUiVu"
      },
      "outputs": [],
      "source": [
        "# Przygotowanie danych\n",
        "texts = sentences['word'].values\n",
        "labels = sentences['final-annotation'].values\n",
        "\n",
        "# Podział na zbiór treningowy i testowy\n",
        "train_texts, test_texts, train_labels, test_labels = train_test_split(\n",
        "    texts, labels, train_size=TRAIN_SIZE, random_state=42\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iAAlp1paUiVv"
      },
      "outputs": [],
      "source": [
        "# Przygotowanie datasetów\n",
        "train_dataset = TokenClassificationDataset(train_texts, train_labels, tokenizer, MAX_LEN)\n",
        "test_dataset = TokenClassificationDataset(test_texts, test_labels, tokenizer, MAX_LEN)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qSuLsjf0myGV",
        "outputId": "a42ee1ae-9073-4142-8cb6-c1307d51e475"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ARuqSJpwUiVv",
        "outputId": "283e1095-c6e8-4d71-d9a2-3df65da7b824"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 1.32180917263031\n",
            "Epoch 11, Loss: 1.3027799129486084\n",
            "Epoch 21, Loss: 1.2619314193725586\n",
            "Epoch 31, Loss: 1.2178276777267456\n",
            "Epoch 41, Loss: 1.184668779373169\n",
            "Epoch 51, Loss: 1.157524824142456\n",
            "Epoch 61, Loss: 1.137104868888855\n",
            "Epoch 71, Loss: 1.1118160486221313\n",
            "Epoch 81, Loss: 1.0921175479888916\n",
            "Epoch 91, Loss: 1.0667426586151123\n",
            "Epoch 101, Loss: 1.0231467485427856\n",
            "Epoch 111, Loss: 0.9728987812995911\n",
            "Epoch 121, Loss: 0.912367582321167\n",
            "Epoch 131, Loss: 0.847463846206665\n",
            "Epoch 141, Loss: 0.7570992112159729\n",
            "Epoch 151, Loss: 0.703957736492157\n",
            "Epoch 161, Loss: 0.6215837001800537\n",
            "Epoch 171, Loss: 0.574069619178772\n",
            "Epoch 181, Loss: 0.5117709636688232\n",
            "Epoch 191, Loss: 0.4465044438838959\n",
            "Epoch 201, Loss: 0.42718708515167236\n",
            "Epoch 211, Loss: 0.383780837059021\n",
            "Epoch 221, Loss: 0.3626765310764313\n",
            "Epoch 231, Loss: 0.3093695640563965\n",
            "Epoch 241, Loss: 0.322110116481781\n",
            "Epoch 251, Loss: 0.2913350760936737\n",
            "Epoch 261, Loss: 0.27836787700653076\n",
            "Epoch 271, Loss: 0.225826695561409\n",
            "Epoch 281, Loss: 0.21769140660762787\n",
            "Epoch 291, Loss: 0.21328724920749664\n",
            "Epoch 301, Loss: 0.19595539569854736\n",
            "Epoch 311, Loss: 0.19427745044231415\n",
            "Epoch 321, Loss: 0.17656467854976654\n",
            "Epoch 331, Loss: 0.157273530960083\n",
            "Epoch 341, Loss: 0.16511555016040802\n",
            "Epoch 351, Loss: 0.1283828467130661\n",
            "Epoch 361, Loss: 0.12929266691207886\n",
            "Epoch 371, Loss: 0.11843293905258179\n",
            "Epoch 381, Loss: 0.127654030919075\n",
            "Epoch 391, Loss: 0.1002039909362793\n",
            "Epoch 401, Loss: 0.11753904819488525\n",
            "Epoch 411, Loss: 0.07553818821907043\n",
            "Epoch 421, Loss: 0.07728210836648941\n",
            "Epoch 431, Loss: 0.08220749348402023\n",
            "Epoch 441, Loss: 0.0590159073472023\n",
            "Epoch 451, Loss: 0.08723165839910507\n",
            "Epoch 461, Loss: 0.06507088989019394\n",
            "Epoch 471, Loss: 0.07569373399019241\n",
            "Epoch 481, Loss: 0.08705194294452667\n",
            "Epoch 491, Loss: 0.08378905802965164\n",
            "Epoch 501, Loss: 0.052298080176115036\n",
            "Epoch 511, Loss: 0.06344109028577805\n",
            "Epoch 521, Loss: 0.03909486159682274\n",
            "Epoch 531, Loss: 0.05439059063792229\n",
            "Epoch 541, Loss: 0.04844163730740547\n",
            "Epoch 551, Loss: 0.05742857605218887\n",
            "Epoch 561, Loss: 0.03162403404712677\n",
            "Epoch 571, Loss: 0.03712444752454758\n",
            "Epoch 581, Loss: 0.027071921154856682\n",
            "Epoch 591, Loss: 0.033009763807058334\n",
            "Epoch 601, Loss: 0.04066618159413338\n",
            "Epoch 611, Loss: 0.02686426043510437\n",
            "Epoch 621, Loss: 0.03354487195611\n",
            "Epoch 631, Loss: 0.03861992061138153\n",
            "Epoch 641, Loss: 0.022130291908979416\n",
            "Epoch 651, Loss: 0.030026404187083244\n",
            "Epoch 661, Loss: 0.018261386081576347\n",
            "Epoch 671, Loss: 0.040834419429302216\n",
            "Epoch 681, Loss: 0.019707301631569862\n",
            "Epoch 691, Loss: 0.02767939865589142\n",
            "Epoch 701, Loss: 0.018223073333501816\n",
            "Epoch 711, Loss: 0.03773774579167366\n",
            "Epoch 721, Loss: 0.02611006423830986\n",
            "Epoch 731, Loss: 0.017645491287112236\n",
            "Epoch 741, Loss: 0.014077368192374706\n",
            "Epoch 751, Loss: 0.019215380772948265\n",
            "Epoch 761, Loss: 0.017942244186997414\n",
            "Epoch 771, Loss: 0.014408815652132034\n",
            "Epoch 781, Loss: 0.018268262967467308\n",
            "Epoch 791, Loss: 0.014924718998372555\n",
            "Epoch 801, Loss: 0.01299318764358759\n",
            "Epoch 811, Loss: 0.03777842968702316\n",
            "Epoch 821, Loss: 0.017221827059984207\n",
            "Epoch 831, Loss: 0.01295554917305708\n",
            "Epoch 841, Loss: 0.014517209492623806\n",
            "Epoch 851, Loss: 0.026528844609856606\n",
            "Epoch 861, Loss: 0.011014609597623348\n",
            "Epoch 871, Loss: 0.013126032426953316\n",
            "Epoch 881, Loss: 0.020543737336993217\n",
            "Epoch 891, Loss: 0.023380417376756668\n",
            "Epoch 901, Loss: 0.010067644529044628\n",
            "Epoch 911, Loss: 0.01040313858538866\n",
            "Epoch 921, Loss: 0.009593685157597065\n",
            "Epoch 931, Loss: 0.008286619558930397\n",
            "Epoch 941, Loss: 0.010449647903442383\n",
            "Epoch 951, Loss: 0.009990607388317585\n",
            "Epoch 961, Loss: 0.0075379665940999985\n",
            "Epoch 971, Loss: 0.01931772194802761\n",
            "Epoch 981, Loss: 0.033191606402397156\n",
            "Epoch 991, Loss: 0.01096904743462801\n"
          ]
        }
      ],
      "source": [
        "# Trening modelu\n",
        "model.to(device)\n",
        "optimizer = AdamW(model.parameters(), lr=LEARNING_RATE)\n",
        "\n",
        "for epoch in range(1000):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "\n",
        "    for batch in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        input_ids = batch['input_ids'].to(device)\n",
        "        attention_mask = batch['attention_mask'].to(device)\n",
        "        labels = batch['labels'].to(device)\n",
        "\n",
        "        outputs = model(\n",
        "            input_ids=input_ids,\n",
        "            attention_mask=attention_mask,\n",
        "            labels=labels\n",
        "        )\n",
        "\n",
        "        loss = outputs.loss\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    if epoch % 10 == 0:\n",
        "        print(f'Epoch {epoch + 1}, Loss: {total_loss/len(train_loader)}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HzSew8GLUiVw",
        "outputId": "7761f4ba-cc7b-48bc-ee6d-2db774688e35"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Wyniki klasyfikacji:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00        16\n",
            "           1       0.94      0.81      0.87        37\n",
            "           2       0.05      0.50      0.10         2\n",
            "           3       0.71      1.00      0.83        10\n",
            "\n",
            "    accuracy                           0.63        65\n",
            "   macro avg       0.43      0.58      0.45        65\n",
            "weighted avg       0.65      0.63      0.63        65\n",
            "\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Ewaluacja\n",
        "model.eval()\n",
        "predictions = []\n",
        "true_labels = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for batch in test_loader:\n",
        "        input_ids = batch['input_ids'].to(device)\n",
        "        attention_mask = batch['attention_mask'].to(device)\n",
        "        labels = batch['labels'].to(device)\n",
        "\n",
        "        outputs = model(\n",
        "            input_ids=input_ids,\n",
        "            attention_mask=attention_mask\n",
        "        )\n",
        "\n",
        "        preds = torch.argmax(outputs.logits, dim=2)\n",
        "\n",
        "        for i in range(len(preds)):\n",
        "            pred = preds[i][batch['attention_mask'][i] == 1]\n",
        "            label = labels[i][batch['attention_mask'][i] == 1]\n",
        "\n",
        "            pred = pred[label != -100]\n",
        "            label = label[label != -100]\n",
        "\n",
        "            predictions.extend(pred.cpu().numpy())\n",
        "            true_labels.extend(label.cpu().numpy())\n",
        "\n",
        "# Wyświetlenie wyników dla zbioru testowego\n",
        "print(\"\\nWyniki klasyfikacji:\")\n",
        "print(classification_report(true_labels, predictions))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XOFa2sLFUiVx"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Predykcje dla przykładowych zdań ze zbioru testowego\n",
        "label_mapping = {0: 'negatywny', 1: 'neutralny', 2: 'pozytywny', 3: 'inne'}\n",
        "\n",
        "def predict_sentence(sentence_words):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        inputs = tokenizer(\n",
        "            sentence_words,\n",
        "            is_split_into_words=True,\n",
        "            return_tensors='pt',\n",
        "            padding=True,\n",
        "            truncation=True,\n",
        "            max_length=MAX_LEN\n",
        "        ).to(device)\n",
        "\n",
        "        outputs = model(**inputs)\n",
        "        predictions = torch.argmax(outputs.logits, dim=2)\n",
        "\n",
        "        word_predictions = []\n",
        "        word_ids = inputs.word_ids()\n",
        "\n",
        "        current_word = None\n",
        "        current_predictions = []\n",
        "\n",
        "        for token_idx, word_idx in enumerate(word_ids):\n",
        "            if word_idx is None:\n",
        "                continue\n",
        "            if word_idx != current_word:\n",
        "                if current_word is not None:\n",
        "                    # Wybierz najczęstszą predykcję dla słowa\n",
        "                    word_predictions.append(max(set(current_predictions), key=current_predictions.count))\n",
        "                current_word = word_idx\n",
        "                current_predictions = []\n",
        "            current_predictions.append(predictions[0][token_idx].item())\n",
        "\n",
        "        # Dodaj ostatnie słowo\n",
        "        if current_predictions:\n",
        "            word_predictions.append(max(set(current_predictions), key=current_predictions.count))\n",
        "\n",
        "        return word_predictions\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xaSqKCSfUiVx",
        "outputId": "6525f471-6181-4277-e841-13a4164075e2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Przykładowe predykcje dla zdań ze zbioru testowego:\n",
            "\n",
            "Zdanie 1:\n",
            "Słowo: Jakość          Predykcja: neutralny\n",
            "Słowo: i               Predykcja: inne\n",
            "Słowo: praktyczność    Predykcja: pozytywny\n",
            "Słowo: wykonania       Predykcja: neutralny\n",
            "Słowo: tego            Predykcja: inne\n",
            "Słowo: trymera         Predykcja: neutralny\n",
            "Słowo: pozostawia      Predykcja: pozytywny\n",
            "Słowo: naprawdę        Predykcja: pozytywny\n",
            "Słowo: wiele           Predykcja: pozytywny\n",
            "Słowo: do              Predykcja: pozytywny\n",
            "Słowo: życzenia        Predykcja: pozytywny\n",
            "Słowo: O               Predykcja: inne\n",
            "Słowo: golarce         Predykcja: neutralny\n",
            "Słowo: w               Predykcja: inne\n",
            "Słowo: tym             Predykcja: inne\n",
            "Słowo: zestawie        Predykcja: neutralny\n",
            "Słowo: nie             Predykcja: pozytywny\n",
            "Słowo: warto           Predykcja: pozytywny\n",
            "Słowo: nawet           Predykcja: pozytywny\n",
            "Słowo: wspominać       Predykcja: pozytywny\n",
            "Słowo: Lepiej          Predykcja: neutralny\n",
            "Słowo: od              Predykcja: inne\n",
            "Słowo: razu            Predykcja: neutralny\n",
            "Słowo: ja              Predykcja: inne\n",
            "Słowo: wyrzucić        Predykcja: neutralny\n",
            "Słowo: Za              Predykcja: inne\n",
            "Słowo: połowę          Predykcja: neutralny\n",
            "Słowo: ceny            Predykcja: neutralny\n",
            "Słowo: można           Predykcja: neutralny\n",
            "Słowo: kupić           Predykcja: neutralny\n",
            "Słowo: nieco           Predykcja: neutralny\n",
            "Słowo: lepszy          Predykcja: pozytywny\n",
            "Słowo: produkt         Predykcja: neutralny\n",
            "Słowo: produkowany     Predykcja: neutralny\n",
            "Słowo: dla             Predykcja: inne\n",
            "Słowo: marketów        Predykcja: neutralny\n",
            "Słowo: jak             Predykcja: inne\n",
            "Słowo: np              Predykcja: neutralny\n",
            "Słowo: Lidl            Predykcja: neutralny\n",
            "Słowo: Jednym          Predykcja: inne\n",
            "Słowo: słowem          Predykcja: neutralny\n",
            "Słowo: warto           Predykcja: neutralny\n",
            "Słowo: dołożyć         Predykcja: neutralny\n",
            "Słowo: kilkanaście     Predykcja: inne\n",
            "Słowo: złotych         Predykcja: neutralny\n",
            "Słowo: i               Predykcja: inne\n",
            "Słowo: zakupić         Predykcja: neutralny\n",
            "Słowo: np              Predykcja: inne\n",
            "Słowo: Philipsa        Predykcja: neutralny\n",
            "Słowo: Różnica         Predykcja: pozytywny\n",
            "Słowo: kolosalna       Predykcja: pozytywny\n",
            "Słowo: Nie             Predykcja: pozytywny\n",
            "Słowo: polecam         Predykcja: pozytywny\n"
          ]
        }
      ],
      "source": [
        "\n",
        "print(\"\\nPrzykładowe predykcje dla zdań ze zbioru testowego:\")\n",
        "for i in range(min(3, len(test_texts))):  # Pokazujemy pierwsze 3 zdania\n",
        "    sentence = test_texts[i]\n",
        "    predictions = predict_sentence(sentence)\n",
        "\n",
        "    print(f\"\\nZdanie {i+1}:\")\n",
        "    for word, pred in zip(sentence, predictions):\n",
        "        pred_label = label_mapping[pred]\n",
        "        print(f\"Słowo: {word:15} Predykcja: {pred_label}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g0M3kB4lUiVy",
        "outputId": "ec0d987e-d5bb-4962-c491-24f6225873e3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model zapisano w: /content/drive/MyDrive/studia/NLP/NLP-Zad2/save_model/bert_peft_tokens_32\n",
            "Tokenizer zapisano w: /content/drive/MyDrive/studia/NLP/NLP-Zad2/save_model/bert_peft_tokens_32\n"
          ]
        }
      ],
      "source": [
        "# Ścieżki do zapisu\n",
        "model_save_path = \"/content/drive/MyDrive/studia/NLP/NLP-Zad2/save_model/bert_peft_tokens_32\"\n",
        "\n",
        "# Zapis modelu\n",
        "model.save_pretrained(model_save_path)\n",
        "print(f\"Model zapisano w: {model_save_path}\")\n",
        "\n",
        "# Zapis tokenizera\n",
        "tokenizer.save_pretrained(model_save_path)\n",
        "print(f\"Tokenizer zapisano w: {model_save_path}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "original_words_list = []\n",
        "labels_list = []\n",
        "hidden_states_per_layer = []\n",
        "predicted_labels_list = []\n",
        "\n",
        "model.eval()\n",
        "\n",
        "with torch.no_grad():\n",
        "    for batch in test_loader:\n",
        "        # Move input_ids and attention_mask to CPU\n",
        "        input_ids = batch['input_ids'].to(device)\n",
        "        attention_mask = batch['attention_mask'].to(device)\n",
        "        labels = batch['labels'].to(device)\n",
        "\n",
        "        outputs = model(\n",
        "            input_ids=input_ids,\n",
        "            attention_mask=attention_mask,\n",
        "            output_hidden_states=True\n",
        "        )\n",
        "\n",
        "        logits = outputs.logits\n",
        "        predicted_labels = torch.argmax(logits, dim=-1)[attention_mask==1]\n",
        "        predicted_labels = predicted_labels.cpu().numpy()[1:-1]\n",
        "        predicted_labels_list.extend(predicted_labels)\n",
        "\n",
        "        all_hidden_states = outputs.hidden_states  # Lista ukrytych stanów z każdej warstwy\n",
        "        hidden_states_per_layer.append([state.cpu() for state in all_hidden_states])\n",
        "        labels_list.extend(labels.cpu().numpy())\n",
        "\n",
        "        for i, ids in enumerate(input_ids):\n",
        "            words = tokenizer.convert_ids_to_tokens(ids)\n",
        "            valid_words = [word for word, mask in zip(words, attention_mask[i]) if mask == 1]\n",
        "            original_words_list.append(valid_words)\n",
        "\n",
        "# Flatten the list to align with the structure of `labels_list`\n",
        "original_words_list = [word for sentence in original_words_list for word in sentence][1:-1]\n",
        "hidden_states_per_layer = [\n",
        "    [layer.numpy() for layer in batch] for batch in hidden_states_per_layer\n",
        "]\n",
        "labels_list = np.array(labels_list)\n",
        "labels_flat = np.hstack([\n",
        "    batch.flatten() for batch in labels_list\n",
        "])\n",
        "labels_flat = labels_flat[labels_flat != -100]"
      ],
      "metadata": {
        "id": "B4q2MqWXknhq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.manifold import TSNE\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Przygotowanie danych\n",
        "layer_hidden_states = []\n",
        "\n",
        "for layer_idx in range(len(hidden_states_per_layer[0])):\n",
        "    # Spłaszczenie danych dla danej warstwy\n",
        "    layer_flat = np.vstack([\n",
        "        batch[layer_idx].reshape(-1, batch[layer_idx].shape[-1])\n",
        "        for batch in hidden_states_per_layer\n",
        "    ])\n",
        "\n",
        "    # Usunięcie paddingu (-100)\n",
        "    valid_idx = labels_list.flatten() != -100\n",
        "    layer_flat = layer_flat[valid_idx]\n",
        "    layer_hidden_states.append(layer_flat)\n",
        "\n",
        "# Redukcja wymiarowości dla każdej warstwy\n",
        "reduced_embeddings_per_layer = []\n",
        "\n",
        "for i, layer in enumerate(layer_hidden_states):\n",
        "    tsne = TSNE(n_components=2, random_state=42)\n",
        "    reduced_embeddings = tsne.fit_transform(layer)\n",
        "    reduced_embeddings_per_layer.append(reduced_embeddings)\n",
        "num_layers = len(reduced_embeddings_per_layer)"
      ],
      "metadata": {
        "id": "Q4xoL8DllICv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import plotly.express as px\n",
        "import plotly.subplots as sp\n",
        "import pandas as pd\n",
        "\n",
        "# Prepare `words_flat` to align with valid tokens\n",
        "words_flat = np.array(original_words_list)\n",
        "\n",
        "# Prepare interactive plots for each layer\n",
        "fig = sp.make_subplots(\n",
        "    rows=len(reduced_embeddings_per_layer),\n",
        "    cols=1,\n",
        "    subplot_titles=[f\"Layer {i + 1}\" for i in range(len(reduced_embeddings_per_layer))],\n",
        "    vertical_spacing=0.025\n",
        ")\n",
        "\n",
        "for i, reduced_embeddings in enumerate(reduced_embeddings_per_layer):\n",
        "    # Create a DataFrame for easier handling in Plotly\n",
        "    df = pd.DataFrame({\n",
        "        \"Dim1\": reduced_embeddings[:, 0],\n",
        "        \"Dim2\": reduced_embeddings[:, 1],\n",
        "        \"Label\": labels_flat,\n",
        "        \"Predicted_label\": predicted_labels_list,\n",
        "        \"Word\": words_flat\n",
        "    })\n",
        "\n",
        "    # Create the scatter plot\n",
        "    scatter = px.scatter(\n",
        "        df,\n",
        "        x=\"Dim1\",\n",
        "        y=\"Dim2\",\n",
        "        color=\"Predicted_label\",\n",
        "        hover_data={\n",
        "            \"Word\": True,  # Display Word on hover\n",
        "            \"Label\": True,  # Display Label on hover\n",
        "            \"Predicted_label\": True,  # Display Predicted_label on hover\n",
        "            \"Dim1\": False,  # Optionally hide Dim1 and Dim2\n",
        "            \"Dim2\": False\n",
        "        },\n",
        "        title=f\"Layer {i + 1}\",\n",
        "        color_continuous_scale=\"Viridis\"\n",
        "    )\n",
        "\n",
        "    # Add the trace to the subplot\n",
        "    for trace in scatter.data:\n",
        "        fig.add_trace(trace, row=i + 1, col=1)\n",
        "\n",
        "# Update layout for better visualization\n",
        "fig.update_layout(\n",
        "    height=500 * len(reduced_embeddings_per_layer),  # Adjust height based on the number of layers\n",
        "    title_text=\"t-SNE Embedding Visualization Across Layers with Hover Data\",\n",
        "    showlegend=True\n",
        ")\n",
        "\n",
        "fig.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "pTFr5S-plMSY",
        "outputId": "7c46f8ba-f976-483d-a651-b9713a5cd098"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.35.2.min.js\"></script>                <div id=\"5621c445-91db-41a5-b708-069a9812b4e1\" class=\"plotly-graph-div\" style=\"height:6500px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"5621c445-91db-41a5-b708-069a9812b4e1\")) {                    Plotly.newPlot(                        \"5621c445-91db-41a5-b708-069a9812b4e1\",                        [{\"customdata\":[[\"Ja\",1,2],[\"kość\\u003c\\u002fw\\u003e\",1,1],[\"i\\u003c\\u002fw\\u003e\",3,3],[\"prak\",1,2],[\"tyczność\\u003c\\u002fw\\u003e\",1,2],[\"wykonania\\u003c\\u002fw\\u003e\",1,1],[\"tego\\u003c\\u002fw\\u003e\",3,3],[\"try\",1,1],[\"mera\\u003c\\u002fw\\u003e\",1,1],[\"pozostawia\\u003c\\u002fw\\u003e\",0,2],[\"naprawdę\\u003c\\u002fw\\u003e\",0,2],[\"wiele\\u003c\\u002fw\\u003e\",0,2],[\"do\\u003c\\u002fw\\u003e\",0,2],[\"życzenia\\u003c\\u002fw\\u003e\",0,2],[\"O\\u003c\\u002fw\\u003e\",3,3],[\"go\",1,1],[\"lar\",1,1],[\"ce\\u003c\\u002fw\\u003e\",1,1],[\"w\\u003c\\u002fw\\u003e\",3,3],[\"tym\\u003c\\u002fw\\u003e\",3,3],[\"zesta\",1,1],[\"wie\\u003c\\u002fw\\u003e\",1,1],[\"nie\\u003c\\u002fw\\u003e\",0,2],[\"warto\\u003c\\u002fw\\u003e\",0,2],[\"nawet\\u003c\\u002fw\\u003e\",0,2],[\"wspominać\\u003c\\u002fw\\u003e\",0,2],[\"Lepiej\\u003c\\u002fw\\u003e\",1,1],[\"od\\u003c\\u002fw\\u003e\",1,3],[\"razu\\u003c\\u002fw\\u003e\",1,1],[\"ja\\u003c\\u002fw\\u003e\",1,3],[\"wyrzucić\\u003c\\u002fw\\u003e\",0,1],[\"Za\\u003c\\u002fw\\u003e\",3,3],[\"połowę\\u003c\\u002fw\\u003e\",1,1],[\"ceny\\u003c\\u002fw\\u003e\",1,1],[\"można\\u003c\\u002fw\\u003e\",1,1],[\"kupić\\u003c\\u002fw\\u003e\",1,1],[\"nieco\\u003c\\u002fw\\u003e\",1,1],[\"lepszy\\u003c\\u002fw\\u003e\",2,2],[\"produkt\\u003c\\u002fw\\u003e\",1,1],[\"produkowany\\u003c\\u002fw\\u003e\",1,1],[\"dla\\u003c\\u002fw\\u003e\",3,3],[\"marke\",1,1],[\"tów\\u003c\\u002fw\\u003e\",1,1],[\"jak\\u003c\\u002fw\\u003e\",3,3],[\"np\\u003c\\u002fw\\u003e\",1,1],[\"Li\",1,1],[\"d\",1,1],[\"l\\u003c\\u002fw\\u003e\",1,1],[\"Jednym\\u003c\\u002fw\\u003e\",1,3],[\"słowem\\u003c\\u002fw\\u003e\",1,1],[\"warto\\u003c\\u002fw\\u003e\",2,1],[\"dołożyć\\u003c\\u002fw\\u003e\",1,1],[\"kilkanaście\\u003c\\u002fw\\u003e\",3,3],[\"złotych\\u003c\\u002fw\\u003e\",1,1],[\"i\\u003c\\u002fw\\u003e\",3,3],[\"zakupić\\u003c\\u002fw\\u003e\",1,1],[\"np\\u003c\\u002fw\\u003e\",1,3],[\"Philip\",1,1],[\"sa\\u003c\\u002fw\\u003e\",1,1],[\"Różnica\\u003c\\u002fw\\u003e\",0,2],[\"kol\",0,2],[\"os\",0,2],[\"alna\\u003c\\u002fw\\u003e\",0,2],[\"Nie\\u003c\\u002fw\\u003e\",0,2],[\"polecam\\u003c\\u002fw\\u003e\",0,2]],\"hovertemplate\":\"Word=%{customdata[0]}\\u003cbr\\u003eLabel=%{customdata[1]}\\u003cbr\\u003ePredicted_label=%{marker.color}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"\",\"marker\":{\"color\":[2,1,3,2,2,1,3,1,1,2,2,2,2,2,3,1,1,1,3,3,1,1,2,2,2,2,1,3,1,3,1,3,1,1,1,1,1,2,1,1,3,1,1,3,1,1,1,1,3,1,1,1,3,1,3,1,3,1,1,2,2,2,2,2,2],\"coloraxis\":\"coloraxis\",\"symbol\":\"circle\"},\"mode\":\"markers\",\"name\":\"\",\"orientation\":\"v\",\"showlegend\":false,\"x\":[-5.790775,-1.6371527,-3.582887,-3.4604847,-1.570854,-0.27588472,-2.20859,-4.510234,-5.24918,-3.8488188,-0.6552776,-0.40401965,-3.7178733,-0.035123337,-4.3136735,-4.1992364,-6.062173,-3.6060586,-3.3959298,-2.282541,-4.884439,-2.7756102,-2.6406925,0.98660225,-1.2181419,-0.9535807,-1.5688069,-3.4202967,-1.9280359,-5.4386272,0.00022763712,-5.3656197,-2.4426208,-0.6474122,0.41726995,-0.26692283,-0.68507034,0.2636922,-2.1946545,-2.019792,-3.3335195,-4.2478375,-2.0104651,-3.1052234,-1.9341222,-4.7798767,-4.1539793,-4.292771,-0.880657,-2.5923083,1.0369809,0.05764804,0.09066336,0.48826495,-3.624373,-0.5973617,-1.9236553,-5.296187,-4.8966427,-4.480565,-3.8726277,-4.294796,-4.2163935,-2.5712867,1.0944698],\"xaxis\":\"x\",\"y\":[-0.09598411,2.637325,-0.8815998,-2.3300729,2.4210055,-0.52027375,-0.5777612,1.9007796,-1.2896652,-1.4147226,0.38367313,0.9542104,0.35898024,1.5420833,0.8047998,1.3001946,-1.0634273,1.0259492,0.3676199,-0.5671839,0.5448702,1.3891698,1.1149875,-0.3540268,0.12399712,-1.7450874,-1.1296457,-0.013054017,-1.5826727,-0.30425847,-2.254554,0.48400295,-1.7156011,-0.7399567,-0.3418187,-1.2863102,0.8664803,-1.2943953,-2.936751,-2.8998647,-0.0060543236,-1.3217287,-0.64730287,-0.42142677,0.42466882,-0.49649194,0.1210383,-0.03212034,-2.854164,-1.6389763,-0.35791823,-2.220613,0.7858885,0.6322006,-0.8684022,-1.6354098,0.4551512,-2.1516905,-0.9981075,-2.4721725,2.144796,-0.7338297,-2.781358,1.2403923,-0.856617],\"yaxis\":\"y\",\"type\":\"scatter\"},{\"customdata\":[[\"Ja\",1,2],[\"kość\\u003c\\u002fw\\u003e\",1,1],[\"i\\u003c\\u002fw\\u003e\",3,3],[\"prak\",1,2],[\"tyczność\\u003c\\u002fw\\u003e\",1,2],[\"wykonania\\u003c\\u002fw\\u003e\",1,1],[\"tego\\u003c\\u002fw\\u003e\",3,3],[\"try\",1,1],[\"mera\\u003c\\u002fw\\u003e\",1,1],[\"pozostawia\\u003c\\u002fw\\u003e\",0,2],[\"naprawdę\\u003c\\u002fw\\u003e\",0,2],[\"wiele\\u003c\\u002fw\\u003e\",0,2],[\"do\\u003c\\u002fw\\u003e\",0,2],[\"życzenia\\u003c\\u002fw\\u003e\",0,2],[\"O\\u003c\\u002fw\\u003e\",3,3],[\"go\",1,1],[\"lar\",1,1],[\"ce\\u003c\\u002fw\\u003e\",1,1],[\"w\\u003c\\u002fw\\u003e\",3,3],[\"tym\\u003c\\u002fw\\u003e\",3,3],[\"zesta\",1,1],[\"wie\\u003c\\u002fw\\u003e\",1,1],[\"nie\\u003c\\u002fw\\u003e\",0,2],[\"warto\\u003c\\u002fw\\u003e\",0,2],[\"nawet\\u003c\\u002fw\\u003e\",0,2],[\"wspominać\\u003c\\u002fw\\u003e\",0,2],[\"Lepiej\\u003c\\u002fw\\u003e\",1,1],[\"od\\u003c\\u002fw\\u003e\",1,3],[\"razu\\u003c\\u002fw\\u003e\",1,1],[\"ja\\u003c\\u002fw\\u003e\",1,3],[\"wyrzucić\\u003c\\u002fw\\u003e\",0,1],[\"Za\\u003c\\u002fw\\u003e\",3,3],[\"połowę\\u003c\\u002fw\\u003e\",1,1],[\"ceny\\u003c\\u002fw\\u003e\",1,1],[\"można\\u003c\\u002fw\\u003e\",1,1],[\"kupić\\u003c\\u002fw\\u003e\",1,1],[\"nieco\\u003c\\u002fw\\u003e\",1,1],[\"lepszy\\u003c\\u002fw\\u003e\",2,2],[\"produkt\\u003c\\u002fw\\u003e\",1,1],[\"produkowany\\u003c\\u002fw\\u003e\",1,1],[\"dla\\u003c\\u002fw\\u003e\",3,3],[\"marke\",1,1],[\"tów\\u003c\\u002fw\\u003e\",1,1],[\"jak\\u003c\\u002fw\\u003e\",3,3],[\"np\\u003c\\u002fw\\u003e\",1,1],[\"Li\",1,1],[\"d\",1,1],[\"l\\u003c\\u002fw\\u003e\",1,1],[\"Jednym\\u003c\\u002fw\\u003e\",1,3],[\"słowem\\u003c\\u002fw\\u003e\",1,1],[\"warto\\u003c\\u002fw\\u003e\",2,1],[\"dołożyć\\u003c\\u002fw\\u003e\",1,1],[\"kilkanaście\\u003c\\u002fw\\u003e\",3,3],[\"złotych\\u003c\\u002fw\\u003e\",1,1],[\"i\\u003c\\u002fw\\u003e\",3,3],[\"zakupić\\u003c\\u002fw\\u003e\",1,1],[\"np\\u003c\\u002fw\\u003e\",1,3],[\"Philip\",1,1],[\"sa\\u003c\\u002fw\\u003e\",1,1],[\"Różnica\\u003c\\u002fw\\u003e\",0,2],[\"kol\",0,2],[\"os\",0,2],[\"alna\\u003c\\u002fw\\u003e\",0,2],[\"Nie\\u003c\\u002fw\\u003e\",0,2],[\"polecam\\u003c\\u002fw\\u003e\",0,2]],\"hovertemplate\":\"Word=%{customdata[0]}\\u003cbr\\u003eLabel=%{customdata[1]}\\u003cbr\\u003ePredicted_label=%{marker.color}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"\",\"marker\":{\"color\":[2,1,3,2,2,1,3,1,1,2,2,2,2,2,3,1,1,1,3,3,1,1,2,2,2,2,1,3,1,3,1,3,1,1,1,1,1,2,1,1,3,1,1,3,1,1,1,1,3,1,1,1,3,1,3,1,3,1,1,2,2,2,2,2,2],\"coloraxis\":\"coloraxis\",\"symbol\":\"circle\"},\"mode\":\"markers\",\"name\":\"\",\"orientation\":\"v\",\"showlegend\":false,\"x\":[-1.4799441,4.504545,-0.24197663,4.1545877,3.7655804,3.0950434,1.3890816,0.7955658,-2.6695492,0.74152046,2.9214969,2.4107115,-0.53993565,2.4489932,-0.5778477,-0.101653524,-1.9343284,0.22854346,-0.31669116,1.4131715,-0.8377482,0.89548945,0.9463637,0.5837582,1.6030571,1.6351242,-0.4374139,-0.24539849,3.6077497,-1.4716936,1.414991,-1.6634305,2.5976067,-0.41949072,0.42586806,-0.031643957,2.4312246,-0.6406512,-1.768455,-1.6032127,-1.4980239,-2.4978073,-0.96318096,-0.6318288,2.6669867,-2.4014611,-1.4483802,-1.8628309,2.2376714,2.6993525,0.5639152,1.3010035,2.0393865,1.1326251,-0.33626303,0.11820941,2.7025926,-1.5185297,-2.5336165,0.763328,-3.4819038,-3.0762243,-3.2813294,0.89161605,-0.04383679],\"xaxis\":\"x2\",\"y\":[-0.44605607,0.6674466,0.19634736,-0.45746285,0.3007433,-0.014295969,2.223306,3.5965211,-0.9968892,-0.52358764,-1.2680869,-1.5905595,1.7179283,-0.0942669,2.2554638,2.775814,2.9423637,2.1652133,1.46502,2.2277913,3.7144976,1.1655076,0.6882376,-1.5308739,-0.7219521,-1.0354493,-1.6448013,1.0333152,-2.8736403,-0.37594643,-2.7347434,0.098592184,-2.631988,-3.3872144,-1.2421813,-3.076051,-2.0145924,-2.0595856,-2.706144,-2.7693293,1.0325317,-2.707417,0.9919837,-0.556449,1.6012512,2.057841,1.7083,1.7917742,-3.7115586,-3.6041842,-1.6300215,-2.9160852,-2.1545262,-3.3578997,0.17596224,-3.100969,1.5974023,-3.7343068,0.012526942,-4.6338253,0.9868535,0.6471997,-0.41385093,0.5159078,-2.3798068],\"yaxis\":\"y2\",\"type\":\"scatter\"},{\"customdata\":[[\"Ja\",1,2],[\"kość\\u003c\\u002fw\\u003e\",1,1],[\"i\\u003c\\u002fw\\u003e\",3,3],[\"prak\",1,2],[\"tyczność\\u003c\\u002fw\\u003e\",1,2],[\"wykonania\\u003c\\u002fw\\u003e\",1,1],[\"tego\\u003c\\u002fw\\u003e\",3,3],[\"try\",1,1],[\"mera\\u003c\\u002fw\\u003e\",1,1],[\"pozostawia\\u003c\\u002fw\\u003e\",0,2],[\"naprawdę\\u003c\\u002fw\\u003e\",0,2],[\"wiele\\u003c\\u002fw\\u003e\",0,2],[\"do\\u003c\\u002fw\\u003e\",0,2],[\"życzenia\\u003c\\u002fw\\u003e\",0,2],[\"O\\u003c\\u002fw\\u003e\",3,3],[\"go\",1,1],[\"lar\",1,1],[\"ce\\u003c\\u002fw\\u003e\",1,1],[\"w\\u003c\\u002fw\\u003e\",3,3],[\"tym\\u003c\\u002fw\\u003e\",3,3],[\"zesta\",1,1],[\"wie\\u003c\\u002fw\\u003e\",1,1],[\"nie\\u003c\\u002fw\\u003e\",0,2],[\"warto\\u003c\\u002fw\\u003e\",0,2],[\"nawet\\u003c\\u002fw\\u003e\",0,2],[\"wspominać\\u003c\\u002fw\\u003e\",0,2],[\"Lepiej\\u003c\\u002fw\\u003e\",1,1],[\"od\\u003c\\u002fw\\u003e\",1,3],[\"razu\\u003c\\u002fw\\u003e\",1,1],[\"ja\\u003c\\u002fw\\u003e\",1,3],[\"wyrzucić\\u003c\\u002fw\\u003e\",0,1],[\"Za\\u003c\\u002fw\\u003e\",3,3],[\"połowę\\u003c\\u002fw\\u003e\",1,1],[\"ceny\\u003c\\u002fw\\u003e\",1,1],[\"można\\u003c\\u002fw\\u003e\",1,1],[\"kupić\\u003c\\u002fw\\u003e\",1,1],[\"nieco\\u003c\\u002fw\\u003e\",1,1],[\"lepszy\\u003c\\u002fw\\u003e\",2,2],[\"produkt\\u003c\\u002fw\\u003e\",1,1],[\"produkowany\\u003c\\u002fw\\u003e\",1,1],[\"dla\\u003c\\u002fw\\u003e\",3,3],[\"marke\",1,1],[\"tów\\u003c\\u002fw\\u003e\",1,1],[\"jak\\u003c\\u002fw\\u003e\",3,3],[\"np\\u003c\\u002fw\\u003e\",1,1],[\"Li\",1,1],[\"d\",1,1],[\"l\\u003c\\u002fw\\u003e\",1,1],[\"Jednym\\u003c\\u002fw\\u003e\",1,3],[\"słowem\\u003c\\u002fw\\u003e\",1,1],[\"warto\\u003c\\u002fw\\u003e\",2,1],[\"dołożyć\\u003c\\u002fw\\u003e\",1,1],[\"kilkanaście\\u003c\\u002fw\\u003e\",3,3],[\"złotych\\u003c\\u002fw\\u003e\",1,1],[\"i\\u003c\\u002fw\\u003e\",3,3],[\"zakupić\\u003c\\u002fw\\u003e\",1,1],[\"np\\u003c\\u002fw\\u003e\",1,3],[\"Philip\",1,1],[\"sa\\u003c\\u002fw\\u003e\",1,1],[\"Różnica\\u003c\\u002fw\\u003e\",0,2],[\"kol\",0,2],[\"os\",0,2],[\"alna\\u003c\\u002fw\\u003e\",0,2],[\"Nie\\u003c\\u002fw\\u003e\",0,2],[\"polecam\\u003c\\u002fw\\u003e\",0,2]],\"hovertemplate\":\"Word=%{customdata[0]}\\u003cbr\\u003eLabel=%{customdata[1]}\\u003cbr\\u003ePredicted_label=%{marker.color}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"\",\"marker\":{\"color\":[2,1,3,2,2,1,3,1,1,2,2,2,2,2,3,1,1,1,3,3,1,1,2,2,2,2,1,3,1,3,1,3,1,1,1,1,1,2,1,1,3,1,1,3,1,1,1,1,3,1,1,1,3,1,3,1,3,1,1,2,2,2,2,2,2],\"coloraxis\":\"coloraxis\",\"symbol\":\"circle\"},\"mode\":\"markers\",\"name\":\"\",\"orientation\":\"v\",\"showlegend\":false,\"x\":[-3.1896522,-3.4536617,-2.3515308,2.078795,1.9179419,1.5468172,0.6950853,-5.1994705,-4.5390058,-3.8002532,-3.7572327,-0.3010856,-0.1491044,1.4082912,0.49032086,0.32439592,0.1749691,-0.3740031,-0.5224787,0.46651432,0.2629776,-0.49932322,-1.082573,-1.7368785,-2.4318738,-2.7092738,-2.4032786,-1.914513,-3.8571134,-2.7611191,-2.904272,-2.2547169,-2.8571339,-0.8021322,-1.6805288,-1.1288071,-1.3430663,-0.5650036,0.49163213,0.4541921,-1.3527664,1.0150772,-1.1468801,-2.0699282,-3.0430148,-2.0346217,-1.8863367,-1.9495567,-0.683409,-0.6052164,-1.6717366,-2.0452135,-2.253537,-1.9289429,-2.3238375,-1.1434356,-3.1949494,-3.8436673,-3.7769742,-4.1906867,-5.186424,-4.8631506,-4.5551815,-1.5110189,-0.51304436],\"xaxis\":\"x3\",\"y\":[-2.091463,2.7389414,-2.445443,-1.0890055,-1.2027212,-1.3148217,-1.991091,-1.1137521,-1.2227173,-0.88968074,-0.41513044,-1.7518994,-2.8344967,-2.7928925,-3.2251334,-3.7299626,-4.497646,-3.7052586,-2.9467044,-2.1622846,-1.2710439,-1.9945705,-1.9903579,-0.43409064,-0.41766638,-0.041636415,-0.7988312,-1.7381865,0.67285514,-1.7218437,0.35587206,-1.4516562,1.7219634,0.23883212,-0.38895395,0.74502665,1.9848752,1.3192767,0.5752804,0.47696155,-3.0937524,0.7769384,-3.361038,-3.2881918,-3.9640021,-5.1792207,-4.77693,-4.729865,-0.6905361,-0.5252994,-0.3497976,0.8977676,1.0885508,1.1488726,-2.4371812,0.94597846,-3.911033,-4.5365744,-2.9280698,-2.3960705,-3.2507439,-3.1326375,-2.8373613,-1.9963444,1.5948787],\"yaxis\":\"y3\",\"type\":\"scatter\"},{\"customdata\":[[\"Ja\",1,2],[\"kość\\u003c\\u002fw\\u003e\",1,1],[\"i\\u003c\\u002fw\\u003e\",3,3],[\"prak\",1,2],[\"tyczność\\u003c\\u002fw\\u003e\",1,2],[\"wykonania\\u003c\\u002fw\\u003e\",1,1],[\"tego\\u003c\\u002fw\\u003e\",3,3],[\"try\",1,1],[\"mera\\u003c\\u002fw\\u003e\",1,1],[\"pozostawia\\u003c\\u002fw\\u003e\",0,2],[\"naprawdę\\u003c\\u002fw\\u003e\",0,2],[\"wiele\\u003c\\u002fw\\u003e\",0,2],[\"do\\u003c\\u002fw\\u003e\",0,2],[\"życzenia\\u003c\\u002fw\\u003e\",0,2],[\"O\\u003c\\u002fw\\u003e\",3,3],[\"go\",1,1],[\"lar\",1,1],[\"ce\\u003c\\u002fw\\u003e\",1,1],[\"w\\u003c\\u002fw\\u003e\",3,3],[\"tym\\u003c\\u002fw\\u003e\",3,3],[\"zesta\",1,1],[\"wie\\u003c\\u002fw\\u003e\",1,1],[\"nie\\u003c\\u002fw\\u003e\",0,2],[\"warto\\u003c\\u002fw\\u003e\",0,2],[\"nawet\\u003c\\u002fw\\u003e\",0,2],[\"wspominać\\u003c\\u002fw\\u003e\",0,2],[\"Lepiej\\u003c\\u002fw\\u003e\",1,1],[\"od\\u003c\\u002fw\\u003e\",1,3],[\"razu\\u003c\\u002fw\\u003e\",1,1],[\"ja\\u003c\\u002fw\\u003e\",1,3],[\"wyrzucić\\u003c\\u002fw\\u003e\",0,1],[\"Za\\u003c\\u002fw\\u003e\",3,3],[\"połowę\\u003c\\u002fw\\u003e\",1,1],[\"ceny\\u003c\\u002fw\\u003e\",1,1],[\"można\\u003c\\u002fw\\u003e\",1,1],[\"kupić\\u003c\\u002fw\\u003e\",1,1],[\"nieco\\u003c\\u002fw\\u003e\",1,1],[\"lepszy\\u003c\\u002fw\\u003e\",2,2],[\"produkt\\u003c\\u002fw\\u003e\",1,1],[\"produkowany\\u003c\\u002fw\\u003e\",1,1],[\"dla\\u003c\\u002fw\\u003e\",3,3],[\"marke\",1,1],[\"tów\\u003c\\u002fw\\u003e\",1,1],[\"jak\\u003c\\u002fw\\u003e\",3,3],[\"np\\u003c\\u002fw\\u003e\",1,1],[\"Li\",1,1],[\"d\",1,1],[\"l\\u003c\\u002fw\\u003e\",1,1],[\"Jednym\\u003c\\u002fw\\u003e\",1,3],[\"słowem\\u003c\\u002fw\\u003e\",1,1],[\"warto\\u003c\\u002fw\\u003e\",2,1],[\"dołożyć\\u003c\\u002fw\\u003e\",1,1],[\"kilkanaście\\u003c\\u002fw\\u003e\",3,3],[\"złotych\\u003c\\u002fw\\u003e\",1,1],[\"i\\u003c\\u002fw\\u003e\",3,3],[\"zakupić\\u003c\\u002fw\\u003e\",1,1],[\"np\\u003c\\u002fw\\u003e\",1,3],[\"Philip\",1,1],[\"sa\\u003c\\u002fw\\u003e\",1,1],[\"Różnica\\u003c\\u002fw\\u003e\",0,2],[\"kol\",0,2],[\"os\",0,2],[\"alna\\u003c\\u002fw\\u003e\",0,2],[\"Nie\\u003c\\u002fw\\u003e\",0,2],[\"polecam\\u003c\\u002fw\\u003e\",0,2]],\"hovertemplate\":\"Word=%{customdata[0]}\\u003cbr\\u003eLabel=%{customdata[1]}\\u003cbr\\u003ePredicted_label=%{marker.color}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"\",\"marker\":{\"color\":[2,1,3,2,2,1,3,1,1,2,2,2,2,2,3,1,1,1,3,3,1,1,2,2,2,2,1,3,1,3,1,3,1,1,1,1,1,2,1,1,3,1,1,3,1,1,1,1,3,1,1,1,3,1,3,1,3,1,1,2,2,2,2,2,2],\"coloraxis\":\"coloraxis\",\"symbol\":\"circle\"},\"mode\":\"markers\",\"name\":\"\",\"orientation\":\"v\",\"showlegend\":false,\"x\":[3.6172917,1.2996324,4.9212813,4.701577,4.7529964,4.8244314,5.818034,3.4863865,3.6272492,4.831743,6.1006145,6.2010818,6.214151,5.4316077,7.18479,7.678829,8.504928,7.7317557,6.697961,6.2518525,8.178462,7.614669,6.470256,5.5855293,6.4018593,6.446872,5.881038,7.1911287,7.633296,6.452578,6.658757,5.670332,6.107495,4.6548634,4.630178,4.0891666,3.946395,3.4384482,2.459824,2.3929641,2.311007,1.8661177,2.941765,3.4927816,2.617279,0.44628543,0.8324681,1.0639956,4.5471783,4.5608354,5.1849813,5.0954747,5.243663,4.848641,4.6918173,4.070647,2.569873,1.4746095,2.561511,3.3066645,1.4824915,1.7967701,2.1902263,4.1812654,3.4875546],\"xaxis\":\"x4\",\"y\":[7.2529173,6.503671,4.3106313,7.2467823,7.1071143,6.7339916,4.62265,5.800379,5.6439548,5.463788,6.152674,5.7730947,5.207499,5.5764647,5.346444,5.587764,5.309499,4.5583653,4.230851,4.349823,3.5713394,3.8582664,3.5533648,1.9307853,2.1033218,1.6903882,2.3508666,2.6637661,1.757838,2.8748038,1.3598537,2.867839,0.49535462,1.0619094,1.7244453,0.8970244,1.5359337,0.6355845,0.91098475,0.9501464,1.7511842,0.5891176,1.9746454,2.46485,2.9125383,2.1633923,2.3103104,2.3759336,2.809787,2.6619506,1.8350458,0.42612097,0.16386002,0.0012530703,3.8637488,0.46924207,3.0978518,3.6027617,4.121644,3.9982615,5.607275,5.1998696,4.797146,3.6400077,-0.23047245],\"yaxis\":\"y4\",\"type\":\"scatter\"},{\"customdata\":[[\"Ja\",1,2],[\"kość\\u003c\\u002fw\\u003e\",1,1],[\"i\\u003c\\u002fw\\u003e\",3,3],[\"prak\",1,2],[\"tyczność\\u003c\\u002fw\\u003e\",1,2],[\"wykonania\\u003c\\u002fw\\u003e\",1,1],[\"tego\\u003c\\u002fw\\u003e\",3,3],[\"try\",1,1],[\"mera\\u003c\\u002fw\\u003e\",1,1],[\"pozostawia\\u003c\\u002fw\\u003e\",0,2],[\"naprawdę\\u003c\\u002fw\\u003e\",0,2],[\"wiele\\u003c\\u002fw\\u003e\",0,2],[\"do\\u003c\\u002fw\\u003e\",0,2],[\"życzenia\\u003c\\u002fw\\u003e\",0,2],[\"O\\u003c\\u002fw\\u003e\",3,3],[\"go\",1,1],[\"lar\",1,1],[\"ce\\u003c\\u002fw\\u003e\",1,1],[\"w\\u003c\\u002fw\\u003e\",3,3],[\"tym\\u003c\\u002fw\\u003e\",3,3],[\"zesta\",1,1],[\"wie\\u003c\\u002fw\\u003e\",1,1],[\"nie\\u003c\\u002fw\\u003e\",0,2],[\"warto\\u003c\\u002fw\\u003e\",0,2],[\"nawet\\u003c\\u002fw\\u003e\",0,2],[\"wspominać\\u003c\\u002fw\\u003e\",0,2],[\"Lepiej\\u003c\\u002fw\\u003e\",1,1],[\"od\\u003c\\u002fw\\u003e\",1,3],[\"razu\\u003c\\u002fw\\u003e\",1,1],[\"ja\\u003c\\u002fw\\u003e\",1,3],[\"wyrzucić\\u003c\\u002fw\\u003e\",0,1],[\"Za\\u003c\\u002fw\\u003e\",3,3],[\"połowę\\u003c\\u002fw\\u003e\",1,1],[\"ceny\\u003c\\u002fw\\u003e\",1,1],[\"można\\u003c\\u002fw\\u003e\",1,1],[\"kupić\\u003c\\u002fw\\u003e\",1,1],[\"nieco\\u003c\\u002fw\\u003e\",1,1],[\"lepszy\\u003c\\u002fw\\u003e\",2,2],[\"produkt\\u003c\\u002fw\\u003e\",1,1],[\"produkowany\\u003c\\u002fw\\u003e\",1,1],[\"dla\\u003c\\u002fw\\u003e\",3,3],[\"marke\",1,1],[\"tów\\u003c\\u002fw\\u003e\",1,1],[\"jak\\u003c\\u002fw\\u003e\",3,3],[\"np\\u003c\\u002fw\\u003e\",1,1],[\"Li\",1,1],[\"d\",1,1],[\"l\\u003c\\u002fw\\u003e\",1,1],[\"Jednym\\u003c\\u002fw\\u003e\",1,3],[\"słowem\\u003c\\u002fw\\u003e\",1,1],[\"warto\\u003c\\u002fw\\u003e\",2,1],[\"dołożyć\\u003c\\u002fw\\u003e\",1,1],[\"kilkanaście\\u003c\\u002fw\\u003e\",3,3],[\"złotych\\u003c\\u002fw\\u003e\",1,1],[\"i\\u003c\\u002fw\\u003e\",3,3],[\"zakupić\\u003c\\u002fw\\u003e\",1,1],[\"np\\u003c\\u002fw\\u003e\",1,3],[\"Philip\",1,1],[\"sa\\u003c\\u002fw\\u003e\",1,1],[\"Różnica\\u003c\\u002fw\\u003e\",0,2],[\"kol\",0,2],[\"os\",0,2],[\"alna\\u003c\\u002fw\\u003e\",0,2],[\"Nie\\u003c\\u002fw\\u003e\",0,2],[\"polecam\\u003c\\u002fw\\u003e\",0,2]],\"hovertemplate\":\"Word=%{customdata[0]}\\u003cbr\\u003eLabel=%{customdata[1]}\\u003cbr\\u003ePredicted_label=%{marker.color}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"\",\"marker\":{\"color\":[2,1,3,2,2,1,3,1,1,2,2,2,2,2,3,1,1,1,3,3,1,1,2,2,2,2,1,3,1,3,1,3,1,1,1,1,1,2,1,1,3,1,1,3,1,1,1,1,3,1,1,1,3,1,3,1,3,1,1,2,2,2,2,2,2],\"coloraxis\":\"coloraxis\",\"symbol\":\"circle\"},\"mode\":\"markers\",\"name\":\"\",\"orientation\":\"v\",\"showlegend\":false,\"x\":[2.9434152,-3.1617336,1.9403406,3.9383965,3.7455547,3.2893395,2.5020206,4.413841,4.315237,-3.0801573,-3.940534,-3.5975566,-2.9169605,-2.3881483,0.8043085,3.5658658,3.6144404,2.7987635,1.7863574,2.0931273,1.7753797,1.6633074,-2.3481207,-1.2839491,-1.4651011,-1.4687166,-0.7008328,0.032844253,-0.8104882,-0.5315576,-1.3045644,0.10481745,-0.4329092,-1.1727861,-1.5040551,-1.5835253,-2.3749228,-3.2413006,-2.6580963,-2.6740997,-3.430644,-2.6568556,-2.2408123,-1.4832677,-0.6514986,0.8132943,0.6922413,0.6344925,0.39111927,0.36869645,-1.0423328,-0.09488632,0.23794022,-0.22094418,1.3809679,-0.97639084,-0.3239668,0.4074077,1.0348397,1.0296755,2.8366117,2.507356,1.958906,-2.7051525,-3.6816063],\"xaxis\":\"x5\",\"y\":[1.9389265,7.4495373,2.4235215,2.067328,2.1675568,3.021588,3.8882349,4.586114,4.5014896,4.8214483,5.277474,5.500997,5.7099776,6.421288,4.683571,5.62027,5.8812647,5.6732554,4.9624414,4.458657,6.397671,5.884007,3.8683462,3.7975771,4.565682,4.975139,4.476007,5.7330556,6.1825275,5.6370273,5.3720593,4.132547,2.657662,1.801261,2.520386,1.6765888,2.2095764,1.9685074,0.98297805,0.8394913,0.37503743,-0.33288628,-0.032898538,-0.6249982,-0.33706713,8.202668,7.8297095,7.5463605,3.2544525,3.0592198,3.216388,1.7785604,1.4982426,1.2982907,2.3312583,1.1477934,-0.31763288,-1.3092248,-0.25658333,0.53867704,-0.6465774,-0.4981181,-0.23254013,3.205733,2.8487122],\"yaxis\":\"y5\",\"type\":\"scatter\"},{\"customdata\":[[\"Ja\",1,2],[\"kość\\u003c\\u002fw\\u003e\",1,1],[\"i\\u003c\\u002fw\\u003e\",3,3],[\"prak\",1,2],[\"tyczność\\u003c\\u002fw\\u003e\",1,2],[\"wykonania\\u003c\\u002fw\\u003e\",1,1],[\"tego\\u003c\\u002fw\\u003e\",3,3],[\"try\",1,1],[\"mera\\u003c\\u002fw\\u003e\",1,1],[\"pozostawia\\u003c\\u002fw\\u003e\",0,2],[\"naprawdę\\u003c\\u002fw\\u003e\",0,2],[\"wiele\\u003c\\u002fw\\u003e\",0,2],[\"do\\u003c\\u002fw\\u003e\",0,2],[\"życzenia\\u003c\\u002fw\\u003e\",0,2],[\"O\\u003c\\u002fw\\u003e\",3,3],[\"go\",1,1],[\"lar\",1,1],[\"ce\\u003c\\u002fw\\u003e\",1,1],[\"w\\u003c\\u002fw\\u003e\",3,3],[\"tym\\u003c\\u002fw\\u003e\",3,3],[\"zesta\",1,1],[\"wie\\u003c\\u002fw\\u003e\",1,1],[\"nie\\u003c\\u002fw\\u003e\",0,2],[\"warto\\u003c\\u002fw\\u003e\",0,2],[\"nawet\\u003c\\u002fw\\u003e\",0,2],[\"wspominać\\u003c\\u002fw\\u003e\",0,2],[\"Lepiej\\u003c\\u002fw\\u003e\",1,1],[\"od\\u003c\\u002fw\\u003e\",1,3],[\"razu\\u003c\\u002fw\\u003e\",1,1],[\"ja\\u003c\\u002fw\\u003e\",1,3],[\"wyrzucić\\u003c\\u002fw\\u003e\",0,1],[\"Za\\u003c\\u002fw\\u003e\",3,3],[\"połowę\\u003c\\u002fw\\u003e\",1,1],[\"ceny\\u003c\\u002fw\\u003e\",1,1],[\"można\\u003c\\u002fw\\u003e\",1,1],[\"kupić\\u003c\\u002fw\\u003e\",1,1],[\"nieco\\u003c\\u002fw\\u003e\",1,1],[\"lepszy\\u003c\\u002fw\\u003e\",2,2],[\"produkt\\u003c\\u002fw\\u003e\",1,1],[\"produkowany\\u003c\\u002fw\\u003e\",1,1],[\"dla\\u003c\\u002fw\\u003e\",3,3],[\"marke\",1,1],[\"tów\\u003c\\u002fw\\u003e\",1,1],[\"jak\\u003c\\u002fw\\u003e\",3,3],[\"np\\u003c\\u002fw\\u003e\",1,1],[\"Li\",1,1],[\"d\",1,1],[\"l\\u003c\\u002fw\\u003e\",1,1],[\"Jednym\\u003c\\u002fw\\u003e\",1,3],[\"słowem\\u003c\\u002fw\\u003e\",1,1],[\"warto\\u003c\\u002fw\\u003e\",2,1],[\"dołożyć\\u003c\\u002fw\\u003e\",1,1],[\"kilkanaście\\u003c\\u002fw\\u003e\",3,3],[\"złotych\\u003c\\u002fw\\u003e\",1,1],[\"i\\u003c\\u002fw\\u003e\",3,3],[\"zakupić\\u003c\\u002fw\\u003e\",1,1],[\"np\\u003c\\u002fw\\u003e\",1,3],[\"Philip\",1,1],[\"sa\\u003c\\u002fw\\u003e\",1,1],[\"Różnica\\u003c\\u002fw\\u003e\",0,2],[\"kol\",0,2],[\"os\",0,2],[\"alna\\u003c\\u002fw\\u003e\",0,2],[\"Nie\\u003c\\u002fw\\u003e\",0,2],[\"polecam\\u003c\\u002fw\\u003e\",0,2]],\"hovertemplate\":\"Word=%{customdata[0]}\\u003cbr\\u003eLabel=%{customdata[1]}\\u003cbr\\u003ePredicted_label=%{marker.color}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"\",\"marker\":{\"color\":[2,1,3,2,2,1,3,1,1,2,2,2,2,2,3,1,1,1,3,3,1,1,2,2,2,2,1,3,1,3,1,3,1,1,1,1,1,2,1,1,3,1,1,3,1,1,1,1,3,1,1,1,3,1,3,1,3,1,1,2,2,2,2,2,2],\"coloraxis\":\"coloraxis\",\"symbol\":\"circle\"},\"mode\":\"markers\",\"name\":\"\",\"orientation\":\"v\",\"showlegend\":false,\"x\":[-3.6857414,0.8538015,-2.0559335,-3.9097388,-3.714849,-3.5217695,-2.9399872,-3.6922588,-3.6360545,-4.2911534,-5.522901,-5.2075896,-4.804048,-5.372022,-1.1546478,-2.4977515,-2.4602094,-2.0772138,-1.7537582,-2.4989424,-1.7607706,-1.755175,0.8776792,1.2694529,0.19127296,0.11985822,0.60336596,-1.473579,-1.415002,-0.80510366,-0.06943969,4.0231457,4.030635,4.3912992,1.1328108,1.6910166,3.2821393,0.6031082,1.1649265,1.1949106,0.19741966,0.37225583,0.38839284,4.4368525,4.489503,2.1268928,1.91548,1.6633272,3.1493142,3.1443002,1.6083405,2.3124979,2.9842777,3.1300247,-0.938469,1.9079387,4.3617907,2.7065854,2.2160969,2.690243,-0.3110305,-0.16144933,0.18421236,1.3348148,1.5790485],\"xaxis\":\"x6\",\"y\":[3.1513882,6.2544503,1.0007054,2.3579557,2.2574847,1.5430348,-0.024061322,-2.659525,-2.4222178,-0.6867313,-0.6434042,-0.22187182,0.33170804,1.2018192,4.491741,-3.3070192,-3.1758664,-2.4199073,-0.46564755,-0.29644126,-1.4596645,-1.2944897,3.805505,2.3680167,2.9841385,2.3317542,1.4779475,2.652651,2.7911668,1.5405022,1.6626916,1.8314855,0.49941805,1.268955,0.6601742,-0.08909381,-0.36544132,-0.12584066,-1.1583968,-1.3770634,-1.7473049,-2.6333306,-2.410342,-1.6298419,-2.2351332,-4.492015,-4.219209,-3.7964036,2.7566714,2.791419,2.0427012,0.87842906,0.6973097,1.0133133,0.6767592,-0.07760542,-2.3632162,-2.8629754,-2.7313702,-1.5942643,-5.118842,-4.8337593,-4.2158756,4.2001038,5.0715356],\"yaxis\":\"y6\",\"type\":\"scatter\"},{\"customdata\":[[\"Ja\",1,2],[\"kość\\u003c\\u002fw\\u003e\",1,1],[\"i\\u003c\\u002fw\\u003e\",3,3],[\"prak\",1,2],[\"tyczność\\u003c\\u002fw\\u003e\",1,2],[\"wykonania\\u003c\\u002fw\\u003e\",1,1],[\"tego\\u003c\\u002fw\\u003e\",3,3],[\"try\",1,1],[\"mera\\u003c\\u002fw\\u003e\",1,1],[\"pozostawia\\u003c\\u002fw\\u003e\",0,2],[\"naprawdę\\u003c\\u002fw\\u003e\",0,2],[\"wiele\\u003c\\u002fw\\u003e\",0,2],[\"do\\u003c\\u002fw\\u003e\",0,2],[\"życzenia\\u003c\\u002fw\\u003e\",0,2],[\"O\\u003c\\u002fw\\u003e\",3,3],[\"go\",1,1],[\"lar\",1,1],[\"ce\\u003c\\u002fw\\u003e\",1,1],[\"w\\u003c\\u002fw\\u003e\",3,3],[\"tym\\u003c\\u002fw\\u003e\",3,3],[\"zesta\",1,1],[\"wie\\u003c\\u002fw\\u003e\",1,1],[\"nie\\u003c\\u002fw\\u003e\",0,2],[\"warto\\u003c\\u002fw\\u003e\",0,2],[\"nawet\\u003c\\u002fw\\u003e\",0,2],[\"wspominać\\u003c\\u002fw\\u003e\",0,2],[\"Lepiej\\u003c\\u002fw\\u003e\",1,1],[\"od\\u003c\\u002fw\\u003e\",1,3],[\"razu\\u003c\\u002fw\\u003e\",1,1],[\"ja\\u003c\\u002fw\\u003e\",1,3],[\"wyrzucić\\u003c\\u002fw\\u003e\",0,1],[\"Za\\u003c\\u002fw\\u003e\",3,3],[\"połowę\\u003c\\u002fw\\u003e\",1,1],[\"ceny\\u003c\\u002fw\\u003e\",1,1],[\"można\\u003c\\u002fw\\u003e\",1,1],[\"kupić\\u003c\\u002fw\\u003e\",1,1],[\"nieco\\u003c\\u002fw\\u003e\",1,1],[\"lepszy\\u003c\\u002fw\\u003e\",2,2],[\"produkt\\u003c\\u002fw\\u003e\",1,1],[\"produkowany\\u003c\\u002fw\\u003e\",1,1],[\"dla\\u003c\\u002fw\\u003e\",3,3],[\"marke\",1,1],[\"tów\\u003c\\u002fw\\u003e\",1,1],[\"jak\\u003c\\u002fw\\u003e\",3,3],[\"np\\u003c\\u002fw\\u003e\",1,1],[\"Li\",1,1],[\"d\",1,1],[\"l\\u003c\\u002fw\\u003e\",1,1],[\"Jednym\\u003c\\u002fw\\u003e\",1,3],[\"słowem\\u003c\\u002fw\\u003e\",1,1],[\"warto\\u003c\\u002fw\\u003e\",2,1],[\"dołożyć\\u003c\\u002fw\\u003e\",1,1],[\"kilkanaście\\u003c\\u002fw\\u003e\",3,3],[\"złotych\\u003c\\u002fw\\u003e\",1,1],[\"i\\u003c\\u002fw\\u003e\",3,3],[\"zakupić\\u003c\\u002fw\\u003e\",1,1],[\"np\\u003c\\u002fw\\u003e\",1,3],[\"Philip\",1,1],[\"sa\\u003c\\u002fw\\u003e\",1,1],[\"Różnica\\u003c\\u002fw\\u003e\",0,2],[\"kol\",0,2],[\"os\",0,2],[\"alna\\u003c\\u002fw\\u003e\",0,2],[\"Nie\\u003c\\u002fw\\u003e\",0,2],[\"polecam\\u003c\\u002fw\\u003e\",0,2]],\"hovertemplate\":\"Word=%{customdata[0]}\\u003cbr\\u003eLabel=%{customdata[1]}\\u003cbr\\u003ePredicted_label=%{marker.color}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"\",\"marker\":{\"color\":[2,1,3,2,2,1,3,1,1,2,2,2,2,2,3,1,1,1,3,3,1,1,2,2,2,2,1,3,1,3,1,3,1,1,1,1,1,2,1,1,3,1,1,3,1,1,1,1,3,1,1,1,3,1,3,1,3,1,1,2,2,2,2,2,2],\"coloraxis\":\"coloraxis\",\"symbol\":\"circle\"},\"mode\":\"markers\",\"name\":\"\",\"orientation\":\"v\",\"showlegend\":false,\"x\":[-3.9906209,4.9161544,-3.2069814,-3.2307527,-3.18925,-2.2315428,-0.36376715,1.838547,1.5509281,-1.08681,-2.1154683,-1.7584729,-1.2150578,-0.4464945,2.684336,2.6509876,2.6282024,2.132575,1.1019762,0.45158437,1.0254806,1.0812507,2.795184,2.5841029,3.6076906,1.9303542,2.4830456,-0.7336673,-0.70458764,0.43635944,1.0742972,2.5839362,2.126697,1.7644644,0.60350996,0.06376615,-0.5240134,-0.9560385,-1.504066,-2.0085337,-3.0132096,-3.7794535,-3.4630992,-2.1964552,-1.903922,-3.6648376,-3.440083,-3.030379,3.7943344,4.122125,1.5995599,0.82146406,0.721476,0.7265711,-0.43903366,0.046228968,-1.5752089,-1.7288167,-1.5066211,1.4854044,-0.03018173,-0.0019851334,0.15706205,3.1646366,3.3163247],\"xaxis\":\"x7\",\"y\":[6.358249,6.816998,6.9339266,5.872507,6.089756,6.28397,6.6451764,8.749844,8.621305,8.194238,8.441141,8.714891,9.310826,9.235138,5.9946513,7.9299474,7.753437,7.189839,5.9204698,6.2851214,7.0015097,6.705326,4.787177,3.9959576,4.342712,4.2840104,2.9979737,5.0329814,5.0145845,4.641407,3.9923496,1.8632536,0.9040548,1.4715562,2.7372093,2.6334572,3.114009,3.0132487,3.410936,3.5860875,2.8710916,2.4642246,2.4836926,1.7493403,1.2261235,0.0919127,0.15907802,0.24569294,1.9080125,1.9365108,2.7909868,1.4173994,0.79785866,0.84266853,1.7285876,2.1642451,0.99077535,-0.57876015,-0.41750047,-0.5380118,-1.9508569,-1.7144985,-1.1432987,-0.24793738,-0.43764117],\"yaxis\":\"y7\",\"type\":\"scatter\"},{\"customdata\":[[\"Ja\",1,2],[\"kość\\u003c\\u002fw\\u003e\",1,1],[\"i\\u003c\\u002fw\\u003e\",3,3],[\"prak\",1,2],[\"tyczność\\u003c\\u002fw\\u003e\",1,2],[\"wykonania\\u003c\\u002fw\\u003e\",1,1],[\"tego\\u003c\\u002fw\\u003e\",3,3],[\"try\",1,1],[\"mera\\u003c\\u002fw\\u003e\",1,1],[\"pozostawia\\u003c\\u002fw\\u003e\",0,2],[\"naprawdę\\u003c\\u002fw\\u003e\",0,2],[\"wiele\\u003c\\u002fw\\u003e\",0,2],[\"do\\u003c\\u002fw\\u003e\",0,2],[\"życzenia\\u003c\\u002fw\\u003e\",0,2],[\"O\\u003c\\u002fw\\u003e\",3,3],[\"go\",1,1],[\"lar\",1,1],[\"ce\\u003c\\u002fw\\u003e\",1,1],[\"w\\u003c\\u002fw\\u003e\",3,3],[\"tym\\u003c\\u002fw\\u003e\",3,3],[\"zesta\",1,1],[\"wie\\u003c\\u002fw\\u003e\",1,1],[\"nie\\u003c\\u002fw\\u003e\",0,2],[\"warto\\u003c\\u002fw\\u003e\",0,2],[\"nawet\\u003c\\u002fw\\u003e\",0,2],[\"wspominać\\u003c\\u002fw\\u003e\",0,2],[\"Lepiej\\u003c\\u002fw\\u003e\",1,1],[\"od\\u003c\\u002fw\\u003e\",1,3],[\"razu\\u003c\\u002fw\\u003e\",1,1],[\"ja\\u003c\\u002fw\\u003e\",1,3],[\"wyrzucić\\u003c\\u002fw\\u003e\",0,1],[\"Za\\u003c\\u002fw\\u003e\",3,3],[\"połowę\\u003c\\u002fw\\u003e\",1,1],[\"ceny\\u003c\\u002fw\\u003e\",1,1],[\"można\\u003c\\u002fw\\u003e\",1,1],[\"kupić\\u003c\\u002fw\\u003e\",1,1],[\"nieco\\u003c\\u002fw\\u003e\",1,1],[\"lepszy\\u003c\\u002fw\\u003e\",2,2],[\"produkt\\u003c\\u002fw\\u003e\",1,1],[\"produkowany\\u003c\\u002fw\\u003e\",1,1],[\"dla\\u003c\\u002fw\\u003e\",3,3],[\"marke\",1,1],[\"tów\\u003c\\u002fw\\u003e\",1,1],[\"jak\\u003c\\u002fw\\u003e\",3,3],[\"np\\u003c\\u002fw\\u003e\",1,1],[\"Li\",1,1],[\"d\",1,1],[\"l\\u003c\\u002fw\\u003e\",1,1],[\"Jednym\\u003c\\u002fw\\u003e\",1,3],[\"słowem\\u003c\\u002fw\\u003e\",1,1],[\"warto\\u003c\\u002fw\\u003e\",2,1],[\"dołożyć\\u003c\\u002fw\\u003e\",1,1],[\"kilkanaście\\u003c\\u002fw\\u003e\",3,3],[\"złotych\\u003c\\u002fw\\u003e\",1,1],[\"i\\u003c\\u002fw\\u003e\",3,3],[\"zakupić\\u003c\\u002fw\\u003e\",1,1],[\"np\\u003c\\u002fw\\u003e\",1,3],[\"Philip\",1,1],[\"sa\\u003c\\u002fw\\u003e\",1,1],[\"Różnica\\u003c\\u002fw\\u003e\",0,2],[\"kol\",0,2],[\"os\",0,2],[\"alna\\u003c\\u002fw\\u003e\",0,2],[\"Nie\\u003c\\u002fw\\u003e\",0,2],[\"polecam\\u003c\\u002fw\\u003e\",0,2]],\"hovertemplate\":\"Word=%{customdata[0]}\\u003cbr\\u003eLabel=%{customdata[1]}\\u003cbr\\u003ePredicted_label=%{marker.color}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"\",\"marker\":{\"color\":[2,1,3,2,2,1,3,1,1,2,2,2,2,2,3,1,1,1,3,3,1,1,2,2,2,2,1,3,1,3,1,3,1,1,1,1,1,2,1,1,3,1,1,3,1,1,1,1,3,1,1,1,3,1,3,1,3,1,1,2,2,2,2,2,2],\"coloraxis\":\"coloraxis\",\"symbol\":\"circle\"},\"mode\":\"markers\",\"name\":\"\",\"orientation\":\"v\",\"showlegend\":false,\"x\":[4.4863305,5.16896,3.024563,4.0950627,4.007684,3.3214357,1.863854,0.8707478,0.9629036,2.2727954,2.8719218,2.4899614,1.5574747,1.1746757,0.18985006,-0.24389356,-0.24825765,0.0020302264,0.7409951,1.2752293,0.7965424,0.65329844,1.3708066,0.7894636,1.7759541,1.156841,-0.15346086,2.8956354,2.8783777,0.24279739,0.44812688,-0.68475735,-2.354646,-3.2861876,-1.190521,-1.8621739,-1.55891,-1.6942402,-2.3688035,-2.7793484,-3.747018,-4.5889325,-4.3357835,-4.6776023,-3.980748,-3.0252893,-2.9285176,-2.6899717,-0.5919078,-1.1939377,-0.44640857,-2.3702784,-2.9133818,-3.2359443,-0.59272534,-2.0140896,-3.614161,-1.5648423,-1.6099606,-0.09405018,3.601482,3.4273176,2.9189117,1.1867495,1.4240421],\"xaxis\":\"x8\",\"y\":[-1.2673557,2.0402467,-2.4471126,-1.9336181,-1.7694297,-1.4379354,-1.3577871,-4.32289,-4.144848,5.492579,5.7601585,5.91206,6.178143,5.846688,3.0769854,-4.2731504,-4.132356,-3.3353152,-1.4197668,-1.4347355,-2.557483,-2.412453,2.1592963,1.8630624,1.6112368,1.2414403,2.4222267,0.7560348,0.7617422,-0.18557888,0.87539846,3.003987,3.5894852,3.6941884,1.2629883,1.2552403,0.42746642,-0.014842166,-0.072650366,0.14926161,0.37587872,0.7925091,0.67090994,-1.0544719,-1.2267768,-2.9933472,-2.7297294,-2.2852561,3.398195,4.257229,1.7218231,2.48253,2.6768646,2.8128293,0.3301115,1.3955246,-1.1711458,-1.9246156,-1.7487922,3.9454212,3.425106,3.3759906,3.358197,3.7132285,3.9241655],\"yaxis\":\"y8\",\"type\":\"scatter\"},{\"customdata\":[[\"Ja\",1,2],[\"kość\\u003c\\u002fw\\u003e\",1,1],[\"i\\u003c\\u002fw\\u003e\",3,3],[\"prak\",1,2],[\"tyczność\\u003c\\u002fw\\u003e\",1,2],[\"wykonania\\u003c\\u002fw\\u003e\",1,1],[\"tego\\u003c\\u002fw\\u003e\",3,3],[\"try\",1,1],[\"mera\\u003c\\u002fw\\u003e\",1,1],[\"pozostawia\\u003c\\u002fw\\u003e\",0,2],[\"naprawdę\\u003c\\u002fw\\u003e\",0,2],[\"wiele\\u003c\\u002fw\\u003e\",0,2],[\"do\\u003c\\u002fw\\u003e\",0,2],[\"życzenia\\u003c\\u002fw\\u003e\",0,2],[\"O\\u003c\\u002fw\\u003e\",3,3],[\"go\",1,1],[\"lar\",1,1],[\"ce\\u003c\\u002fw\\u003e\",1,1],[\"w\\u003c\\u002fw\\u003e\",3,3],[\"tym\\u003c\\u002fw\\u003e\",3,3],[\"zesta\",1,1],[\"wie\\u003c\\u002fw\\u003e\",1,1],[\"nie\\u003c\\u002fw\\u003e\",0,2],[\"warto\\u003c\\u002fw\\u003e\",0,2],[\"nawet\\u003c\\u002fw\\u003e\",0,2],[\"wspominać\\u003c\\u002fw\\u003e\",0,2],[\"Lepiej\\u003c\\u002fw\\u003e\",1,1],[\"od\\u003c\\u002fw\\u003e\",1,3],[\"razu\\u003c\\u002fw\\u003e\",1,1],[\"ja\\u003c\\u002fw\\u003e\",1,3],[\"wyrzucić\\u003c\\u002fw\\u003e\",0,1],[\"Za\\u003c\\u002fw\\u003e\",3,3],[\"połowę\\u003c\\u002fw\\u003e\",1,1],[\"ceny\\u003c\\u002fw\\u003e\",1,1],[\"można\\u003c\\u002fw\\u003e\",1,1],[\"kupić\\u003c\\u002fw\\u003e\",1,1],[\"nieco\\u003c\\u002fw\\u003e\",1,1],[\"lepszy\\u003c\\u002fw\\u003e\",2,2],[\"produkt\\u003c\\u002fw\\u003e\",1,1],[\"produkowany\\u003c\\u002fw\\u003e\",1,1],[\"dla\\u003c\\u002fw\\u003e\",3,3],[\"marke\",1,1],[\"tów\\u003c\\u002fw\\u003e\",1,1],[\"jak\\u003c\\u002fw\\u003e\",3,3],[\"np\\u003c\\u002fw\\u003e\",1,1],[\"Li\",1,1],[\"d\",1,1],[\"l\\u003c\\u002fw\\u003e\",1,1],[\"Jednym\\u003c\\u002fw\\u003e\",1,3],[\"słowem\\u003c\\u002fw\\u003e\",1,1],[\"warto\\u003c\\u002fw\\u003e\",2,1],[\"dołożyć\\u003c\\u002fw\\u003e\",1,1],[\"kilkanaście\\u003c\\u002fw\\u003e\",3,3],[\"złotych\\u003c\\u002fw\\u003e\",1,1],[\"i\\u003c\\u002fw\\u003e\",3,3],[\"zakupić\\u003c\\u002fw\\u003e\",1,1],[\"np\\u003c\\u002fw\\u003e\",1,3],[\"Philip\",1,1],[\"sa\\u003c\\u002fw\\u003e\",1,1],[\"Różnica\\u003c\\u002fw\\u003e\",0,2],[\"kol\",0,2],[\"os\",0,2],[\"alna\\u003c\\u002fw\\u003e\",0,2],[\"Nie\\u003c\\u002fw\\u003e\",0,2],[\"polecam\\u003c\\u002fw\\u003e\",0,2]],\"hovertemplate\":\"Word=%{customdata[0]}\\u003cbr\\u003eLabel=%{customdata[1]}\\u003cbr\\u003ePredicted_label=%{marker.color}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"\",\"marker\":{\"color\":[2,1,3,2,2,1,3,1,1,2,2,2,2,2,3,1,1,1,3,3,1,1,2,2,2,2,1,3,1,3,1,3,1,1,1,1,1,2,1,1,3,1,1,3,1,1,1,1,3,1,1,1,3,1,3,1,3,1,1,2,2,2,2,2,2],\"coloraxis\":\"coloraxis\",\"symbol\":\"circle\"},\"mode\":\"markers\",\"name\":\"\",\"orientation\":\"v\",\"showlegend\":false,\"x\":[0.88661635,2.9654171,0.56554115,0.23829964,0.23981187,-0.40164,-0.5505673,-3.8995764,-3.6610475,-1.9849602,-2.6349232,-2.292407,-1.7651536,-1.3121696,-0.6391687,-3.8551598,-3.688552,-2.9013474,-1.210172,-0.8235588,-2.114156,-2.0917177,-2.985084,-2.2808452,-2.9756823,-2.2429914,-1.5530523,-4.8805857,-4.8951526,-1.7462326,-1.2417991,-0.42030793,0.6604824,1.2176446,0.12434157,0.06227035,1.1959617,1.3463259,0.7411734,0.95045906,1.8477505,2.6917126,2.4313388,3.5297925,3.0945385,-4.3435526,-4.090411,-3.6948705,-0.8192426,-1.2438736,-1.5155613,-0.47891775,-0.034917165,0.058302253,-0.5261895,-0.46012932,2.7152245,-2.6738875,-2.6581833,0.62726045,2.3306358,2.2143922,1.7687212,-2.878755,-3.0871818],\"xaxis\":\"x9\",\"y\":[4.219466,4.583636,5.2861357,4.0380435,4.2822857,4.6247926,6.1746,5.380496,5.287658,2.9317222,2.8955433,2.6189182,2.0709062,1.9978079,7.8767657,6.273839,6.335677,6.4525623,6.808963,6.4571013,5.7675657,6.08201,12.220597,12.3605995,13.197622,13.04783,10.497074,11.35578,11.382285,9.585242,10.985064,9.062556,12.568302,12.929884,10.724748,10.749513,11.151788,10.759269,9.629935,9.409476,9.031281,8.697783,8.819114,10.258999,10.627136,8.327892,8.350439,8.375467,8.899814,8.768615,11.958339,12.203089,13.019887,13.188162,9.961659,10.774601,10.667198,8.171133,8.235886,8.000541,6.6708565,6.7196364,6.926092,10.475758,10.50769],\"yaxis\":\"y9\",\"type\":\"scatter\"},{\"customdata\":[[\"Ja\",1,2],[\"kość\\u003c\\u002fw\\u003e\",1,1],[\"i\\u003c\\u002fw\\u003e\",3,3],[\"prak\",1,2],[\"tyczność\\u003c\\u002fw\\u003e\",1,2],[\"wykonania\\u003c\\u002fw\\u003e\",1,1],[\"tego\\u003c\\u002fw\\u003e\",3,3],[\"try\",1,1],[\"mera\\u003c\\u002fw\\u003e\",1,1],[\"pozostawia\\u003c\\u002fw\\u003e\",0,2],[\"naprawdę\\u003c\\u002fw\\u003e\",0,2],[\"wiele\\u003c\\u002fw\\u003e\",0,2],[\"do\\u003c\\u002fw\\u003e\",0,2],[\"życzenia\\u003c\\u002fw\\u003e\",0,2],[\"O\\u003c\\u002fw\\u003e\",3,3],[\"go\",1,1],[\"lar\",1,1],[\"ce\\u003c\\u002fw\\u003e\",1,1],[\"w\\u003c\\u002fw\\u003e\",3,3],[\"tym\\u003c\\u002fw\\u003e\",3,3],[\"zesta\",1,1],[\"wie\\u003c\\u002fw\\u003e\",1,1],[\"nie\\u003c\\u002fw\\u003e\",0,2],[\"warto\\u003c\\u002fw\\u003e\",0,2],[\"nawet\\u003c\\u002fw\\u003e\",0,2],[\"wspominać\\u003c\\u002fw\\u003e\",0,2],[\"Lepiej\\u003c\\u002fw\\u003e\",1,1],[\"od\\u003c\\u002fw\\u003e\",1,3],[\"razu\\u003c\\u002fw\\u003e\",1,1],[\"ja\\u003c\\u002fw\\u003e\",1,3],[\"wyrzucić\\u003c\\u002fw\\u003e\",0,1],[\"Za\\u003c\\u002fw\\u003e\",3,3],[\"połowę\\u003c\\u002fw\\u003e\",1,1],[\"ceny\\u003c\\u002fw\\u003e\",1,1],[\"można\\u003c\\u002fw\\u003e\",1,1],[\"kupić\\u003c\\u002fw\\u003e\",1,1],[\"nieco\\u003c\\u002fw\\u003e\",1,1],[\"lepszy\\u003c\\u002fw\\u003e\",2,2],[\"produkt\\u003c\\u002fw\\u003e\",1,1],[\"produkowany\\u003c\\u002fw\\u003e\",1,1],[\"dla\\u003c\\u002fw\\u003e\",3,3],[\"marke\",1,1],[\"tów\\u003c\\u002fw\\u003e\",1,1],[\"jak\\u003c\\u002fw\\u003e\",3,3],[\"np\\u003c\\u002fw\\u003e\",1,1],[\"Li\",1,1],[\"d\",1,1],[\"l\\u003c\\u002fw\\u003e\",1,1],[\"Jednym\\u003c\\u002fw\\u003e\",1,3],[\"słowem\\u003c\\u002fw\\u003e\",1,1],[\"warto\\u003c\\u002fw\\u003e\",2,1],[\"dołożyć\\u003c\\u002fw\\u003e\",1,1],[\"kilkanaście\\u003c\\u002fw\\u003e\",3,3],[\"złotych\\u003c\\u002fw\\u003e\",1,1],[\"i\\u003c\\u002fw\\u003e\",3,3],[\"zakupić\\u003c\\u002fw\\u003e\",1,1],[\"np\\u003c\\u002fw\\u003e\",1,3],[\"Philip\",1,1],[\"sa\\u003c\\u002fw\\u003e\",1,1],[\"Różnica\\u003c\\u002fw\\u003e\",0,2],[\"kol\",0,2],[\"os\",0,2],[\"alna\\u003c\\u002fw\\u003e\",0,2],[\"Nie\\u003c\\u002fw\\u003e\",0,2],[\"polecam\\u003c\\u002fw\\u003e\",0,2]],\"hovertemplate\":\"Word=%{customdata[0]}\\u003cbr\\u003eLabel=%{customdata[1]}\\u003cbr\\u003ePredicted_label=%{marker.color}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"\",\"marker\":{\"color\":[2,1,3,2,2,1,3,1,1,2,2,2,2,2,3,1,1,1,3,3,1,1,2,2,2,2,1,3,1,3,1,3,1,1,1,1,1,2,1,1,3,1,1,3,1,1,1,1,3,1,1,1,3,1,3,1,3,1,1,2,2,2,2,2,2],\"coloraxis\":\"coloraxis\",\"symbol\":\"circle\"},\"mode\":\"markers\",\"name\":\"\",\"orientation\":\"v\",\"showlegend\":false,\"x\":[-2.948263,-4.2035255,-3.212693,-2.19627,-2.5128,-2.0366707,-1.939933,0.8775996,0.83257496,5.5114636,6.0892296,5.8756685,5.4140515,5.0900702,-1.6757166,0.99277794,0.95349216,0.6145547,-1.6814934,-1.7615612,-0.46747407,-0.42681727,2.3068974,1.5630287,2.2689915,2.1314237,0.839295,-0.38574785,-0.33607173,-0.5431913,1.4243203,-1.4557552,-0.9796004,-1.2388222,0.8244788,0.5052827,1.7904721,2.0518324,0.8801898,0.6379314,-0.41955727,0.36814973,0.19912161,-2.9323866,-3.7100127,2.6249235,2.3425357,2.0113738,-2.1710308,-2.8716552,0.878046,-0.2746861,-1.1438261,-1.2967968,-1.3965454,0.13168484,-3.6050413,2.3148282,2.050687,3.547644,4.7253647,4.5877647,4.2718973,3.5833156,3.6069515],\"xaxis\":\"x10\",\"y\":[-3.897762,-1.0538263,-3.1735985,-4.2192564,-3.8582892,-3.4254262,-1.429884,-3.8052793,-3.9883966,3.3142827,3.322546,3.8227408,4.379681,4.5963655,0.2993664,-2.8829017,-2.8277733,-2.3186493,-0.4930045,-1.0304892,-2.2678914,-2.0424817,4.973561,5.0164304,5.4003,4.1026955,3.7096431,5.9885755,6.054726,1.4509499,3.138939,1.2313317,3.144345,3.0820684,2.1149302,2.1058617,1.7547314,1.3316227,0.7446189,0.7761003,-0.03309963,-0.6220791,-0.4551472,0.47131822,1.1661793,-1.9923716,-1.8239285,-1.5209203,2.1701448,3.1789699,4.621367,3.7428222,4.137084,4.0565567,1.1801617,2.345801,1.2549267,-0.66656774,-0.76980174,1.7044444,1.0884404,1.1701332,1.6002796,2.8188477,3.0233219],\"yaxis\":\"y10\",\"type\":\"scatter\"},{\"customdata\":[[\"Ja\",1,2],[\"kość\\u003c\\u002fw\\u003e\",1,1],[\"i\\u003c\\u002fw\\u003e\",3,3],[\"prak\",1,2],[\"tyczność\\u003c\\u002fw\\u003e\",1,2],[\"wykonania\\u003c\\u002fw\\u003e\",1,1],[\"tego\\u003c\\u002fw\\u003e\",3,3],[\"try\",1,1],[\"mera\\u003c\\u002fw\\u003e\",1,1],[\"pozostawia\\u003c\\u002fw\\u003e\",0,2],[\"naprawdę\\u003c\\u002fw\\u003e\",0,2],[\"wiele\\u003c\\u002fw\\u003e\",0,2],[\"do\\u003c\\u002fw\\u003e\",0,2],[\"życzenia\\u003c\\u002fw\\u003e\",0,2],[\"O\\u003c\\u002fw\\u003e\",3,3],[\"go\",1,1],[\"lar\",1,1],[\"ce\\u003c\\u002fw\\u003e\",1,1],[\"w\\u003c\\u002fw\\u003e\",3,3],[\"tym\\u003c\\u002fw\\u003e\",3,3],[\"zesta\",1,1],[\"wie\\u003c\\u002fw\\u003e\",1,1],[\"nie\\u003c\\u002fw\\u003e\",0,2],[\"warto\\u003c\\u002fw\\u003e\",0,2],[\"nawet\\u003c\\u002fw\\u003e\",0,2],[\"wspominać\\u003c\\u002fw\\u003e\",0,2],[\"Lepiej\\u003c\\u002fw\\u003e\",1,1],[\"od\\u003c\\u002fw\\u003e\",1,3],[\"razu\\u003c\\u002fw\\u003e\",1,1],[\"ja\\u003c\\u002fw\\u003e\",1,3],[\"wyrzucić\\u003c\\u002fw\\u003e\",0,1],[\"Za\\u003c\\u002fw\\u003e\",3,3],[\"połowę\\u003c\\u002fw\\u003e\",1,1],[\"ceny\\u003c\\u002fw\\u003e\",1,1],[\"można\\u003c\\u002fw\\u003e\",1,1],[\"kupić\\u003c\\u002fw\\u003e\",1,1],[\"nieco\\u003c\\u002fw\\u003e\",1,1],[\"lepszy\\u003c\\u002fw\\u003e\",2,2],[\"produkt\\u003c\\u002fw\\u003e\",1,1],[\"produkowany\\u003c\\u002fw\\u003e\",1,1],[\"dla\\u003c\\u002fw\\u003e\",3,3],[\"marke\",1,1],[\"tów\\u003c\\u002fw\\u003e\",1,1],[\"jak\\u003c\\u002fw\\u003e\",3,3],[\"np\\u003c\\u002fw\\u003e\",1,1],[\"Li\",1,1],[\"d\",1,1],[\"l\\u003c\\u002fw\\u003e\",1,1],[\"Jednym\\u003c\\u002fw\\u003e\",1,3],[\"słowem\\u003c\\u002fw\\u003e\",1,1],[\"warto\\u003c\\u002fw\\u003e\",2,1],[\"dołożyć\\u003c\\u002fw\\u003e\",1,1],[\"kilkanaście\\u003c\\u002fw\\u003e\",3,3],[\"złotych\\u003c\\u002fw\\u003e\",1,1],[\"i\\u003c\\u002fw\\u003e\",3,3],[\"zakupić\\u003c\\u002fw\\u003e\",1,1],[\"np\\u003c\\u002fw\\u003e\",1,3],[\"Philip\",1,1],[\"sa\\u003c\\u002fw\\u003e\",1,1],[\"Różnica\\u003c\\u002fw\\u003e\",0,2],[\"kol\",0,2],[\"os\",0,2],[\"alna\\u003c\\u002fw\\u003e\",0,2],[\"Nie\\u003c\\u002fw\\u003e\",0,2],[\"polecam\\u003c\\u002fw\\u003e\",0,2]],\"hovertemplate\":\"Word=%{customdata[0]}\\u003cbr\\u003eLabel=%{customdata[1]}\\u003cbr\\u003ePredicted_label=%{marker.color}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"\",\"marker\":{\"color\":[2,1,3,2,2,1,3,1,1,2,2,2,2,2,3,1,1,1,3,3,1,1,2,2,2,2,1,3,1,3,1,3,1,1,1,1,1,2,1,1,3,1,1,3,1,1,1,1,3,1,1,1,3,1,3,1,3,1,1,2,2,2,2,2,2],\"coloraxis\":\"coloraxis\",\"symbol\":\"circle\"},\"mode\":\"markers\",\"name\":\"\",\"orientation\":\"v\",\"showlegend\":false,\"x\":[4.3110476,-3.4254735,4.351909,3.956775,4.071071,3.7472293,-3.013635,-0.41902107,-0.10338863,-2.161202,-2.307781,-2.4882512,-2.7799604,-3.028235,-1.9786792,-0.6755559,-0.72843355,-0.9081795,-2.3481662,-2.7740982,-1.8683554,-1.7631301,1.6356272,1.5487998,2.2788236,2.749206,0.14257982,-1.0853755,-0.7675731,-0.7329495,2.3909192,-1.4594065,1.7829326,1.4286222,0.21494564,0.5531051,3.217323,3.4948442,0.8786787,1.4318569,-0.5757306,0.18781805,0.017428176,-1.1952481,-1.3200402,0.27262563,0.36101165,0.40266088,-0.21727565,2.029296,0.82843256,1.738117,1.4734077,1.4626575,-1.2411637,0.6799362,-1.0602683,1.2705581,1.166153,-1.0377465,-0.75205064,-0.6914413,-0.5355245,0.37023744,0.44286934],\"xaxis\":\"x11\",\"y\":[-1.5666752,2.7889311,-1.2876788,-2.0251627,-1.687901,-1.5572592,-0.7293185,-3.9915366,-4.210238,5.2785206,5.2310543,4.8439193,4.503428,4.093435,0.47471797,-3.227901,-3.2420917,-2.8990536,0.026699167,-0.43732116,-2.9356418,-2.7257411,3.998791,3.7984657,3.9410837,3.8947208,2.6224527,2.0072148,2.2582774,0.9776995,0.74181134,0.7690826,1.0349604,1.2438551,1.3828557,0.74016374,1.8922644,2.0296075,-0.20192829,-0.28265175,-0.3793266,-1.257569,-1.1293758,-0.4045042,-0.98377097,-2.1386476,-2.1851573,-2.0549192,0.32247892,0.01583577,2.9886625,1.9694556,1.9575522,1.8311825,0.6160614,0.23436433,-0.66871405,-2.7059376,-2.4983802,5.545166,4.7084804,4.6471076,4.680132,5.135161,5.242627],\"yaxis\":\"y11\",\"type\":\"scatter\"},{\"customdata\":[[\"Ja\",1,2],[\"kość\\u003c\\u002fw\\u003e\",1,1],[\"i\\u003c\\u002fw\\u003e\",3,3],[\"prak\",1,2],[\"tyczność\\u003c\\u002fw\\u003e\",1,2],[\"wykonania\\u003c\\u002fw\\u003e\",1,1],[\"tego\\u003c\\u002fw\\u003e\",3,3],[\"try\",1,1],[\"mera\\u003c\\u002fw\\u003e\",1,1],[\"pozostawia\\u003c\\u002fw\\u003e\",0,2],[\"naprawdę\\u003c\\u002fw\\u003e\",0,2],[\"wiele\\u003c\\u002fw\\u003e\",0,2],[\"do\\u003c\\u002fw\\u003e\",0,2],[\"życzenia\\u003c\\u002fw\\u003e\",0,2],[\"O\\u003c\\u002fw\\u003e\",3,3],[\"go\",1,1],[\"lar\",1,1],[\"ce\\u003c\\u002fw\\u003e\",1,1],[\"w\\u003c\\u002fw\\u003e\",3,3],[\"tym\\u003c\\u002fw\\u003e\",3,3],[\"zesta\",1,1],[\"wie\\u003c\\u002fw\\u003e\",1,1],[\"nie\\u003c\\u002fw\\u003e\",0,2],[\"warto\\u003c\\u002fw\\u003e\",0,2],[\"nawet\\u003c\\u002fw\\u003e\",0,2],[\"wspominać\\u003c\\u002fw\\u003e\",0,2],[\"Lepiej\\u003c\\u002fw\\u003e\",1,1],[\"od\\u003c\\u002fw\\u003e\",1,3],[\"razu\\u003c\\u002fw\\u003e\",1,1],[\"ja\\u003c\\u002fw\\u003e\",1,3],[\"wyrzucić\\u003c\\u002fw\\u003e\",0,1],[\"Za\\u003c\\u002fw\\u003e\",3,3],[\"połowę\\u003c\\u002fw\\u003e\",1,1],[\"ceny\\u003c\\u002fw\\u003e\",1,1],[\"można\\u003c\\u002fw\\u003e\",1,1],[\"kupić\\u003c\\u002fw\\u003e\",1,1],[\"nieco\\u003c\\u002fw\\u003e\",1,1],[\"lepszy\\u003c\\u002fw\\u003e\",2,2],[\"produkt\\u003c\\u002fw\\u003e\",1,1],[\"produkowany\\u003c\\u002fw\\u003e\",1,1],[\"dla\\u003c\\u002fw\\u003e\",3,3],[\"marke\",1,1],[\"tów\\u003c\\u002fw\\u003e\",1,1],[\"jak\\u003c\\u002fw\\u003e\",3,3],[\"np\\u003c\\u002fw\\u003e\",1,1],[\"Li\",1,1],[\"d\",1,1],[\"l\\u003c\\u002fw\\u003e\",1,1],[\"Jednym\\u003c\\u002fw\\u003e\",1,3],[\"słowem\\u003c\\u002fw\\u003e\",1,1],[\"warto\\u003c\\u002fw\\u003e\",2,1],[\"dołożyć\\u003c\\u002fw\\u003e\",1,1],[\"kilkanaście\\u003c\\u002fw\\u003e\",3,3],[\"złotych\\u003c\\u002fw\\u003e\",1,1],[\"i\\u003c\\u002fw\\u003e\",3,3],[\"zakupić\\u003c\\u002fw\\u003e\",1,1],[\"np\\u003c\\u002fw\\u003e\",1,3],[\"Philip\",1,1],[\"sa\\u003c\\u002fw\\u003e\",1,1],[\"Różnica\\u003c\\u002fw\\u003e\",0,2],[\"kol\",0,2],[\"os\",0,2],[\"alna\\u003c\\u002fw\\u003e\",0,2],[\"Nie\\u003c\\u002fw\\u003e\",0,2],[\"polecam\\u003c\\u002fw\\u003e\",0,2]],\"hovertemplate\":\"Word=%{customdata[0]}\\u003cbr\\u003eLabel=%{customdata[1]}\\u003cbr\\u003ePredicted_label=%{marker.color}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"\",\"marker\":{\"color\":[2,1,3,2,2,1,3,1,1,2,2,2,2,2,3,1,1,1,3,3,1,1,2,2,2,2,1,3,1,3,1,3,1,1,1,1,1,2,1,1,3,1,1,3,1,1,1,1,3,1,1,1,3,1,3,1,3,1,1,2,2,2,2,2,2],\"coloraxis\":\"coloraxis\",\"symbol\":\"circle\"},\"mode\":\"markers\",\"name\":\"\",\"orientation\":\"v\",\"showlegend\":false,\"x\":[-3.6597958,-3.2155724,-3.5198143,-3.4943979,-3.5463595,-3.406803,-0.6511981,0.9979997,1.3964056,5.6164722,5.3344746,5.6508603,6.012683,6.223568,-1.4598651,0.022529272,0.14428993,0.2781504,-1.4618775,-0.9110987,1.1116655,0.96792567,3.194694,3.7703307,3.8449972,4.202844,2.5997744,-0.74701625,1.9008787,-0.31227648,1.822751,-1.46225,1.19339,1.0691473,0.49166623,0.6657875,2.1710165,3.6607366,0.9845212,0.98587775,-1.450003,-0.8048558,-0.7839354,-1.2660936,-0.8510348,-0.95103025,-0.6670068,-0.52568495,-0.2120341,1.648981,2.1965506,1.616494,1.0648721,1.0475608,-1.5420641,0.92537946,-0.756753,0.27803987,0.22100623,4.509812,4.753535,4.6116247,4.632525,4.8121667,5.21822],\"xaxis\":\"x12\",\"y\":[1.0088834,-2.2347775,0.7228155,1.4143778,1.1694154,1.1481744,-2.00877,3.3319058,3.1590965,-0.8800865,-1.2094,-1.0529586,-1.0296949,-0.48977476,-2.2971263,3.2528143,3.1131775,2.8727734,-2.2528863,-2.3941872,2.6516368,2.619007,-2.1538253,-1.8288459,-2.171976,-2.4494255,-0.6943296,-1.4746729,-0.41491565,-1.7062895,-2.463111,-1.8679925,-1.6968774,-0.41429976,-0.41436064,-0.054926656,0.036177255,0.7612275,0.32665274,-2.6552474,-1.1527646,0.99706644,0.62766457,-1.0240653,-0.21057421,1.9230522,2.0684657,1.8170884,-2.9610972,0.85699624,-0.9017951,-1.4657044,-1.3365649,-1.1546063,-1.661001,0.91393816,-0.7597887,1.6246527,1.6071696,-0.37092528,0.6140234,0.751447,0.70436776,-0.039306898,0.26710093],\"yaxis\":\"y12\",\"type\":\"scatter\"},{\"customdata\":[[\"Ja\",1,2],[\"kość\\u003c\\u002fw\\u003e\",1,1],[\"i\\u003c\\u002fw\\u003e\",3,3],[\"prak\",1,2],[\"tyczność\\u003c\\u002fw\\u003e\",1,2],[\"wykonania\\u003c\\u002fw\\u003e\",1,1],[\"tego\\u003c\\u002fw\\u003e\",3,3],[\"try\",1,1],[\"mera\\u003c\\u002fw\\u003e\",1,1],[\"pozostawia\\u003c\\u002fw\\u003e\",0,2],[\"naprawdę\\u003c\\u002fw\\u003e\",0,2],[\"wiele\\u003c\\u002fw\\u003e\",0,2],[\"do\\u003c\\u002fw\\u003e\",0,2],[\"życzenia\\u003c\\u002fw\\u003e\",0,2],[\"O\\u003c\\u002fw\\u003e\",3,3],[\"go\",1,1],[\"lar\",1,1],[\"ce\\u003c\\u002fw\\u003e\",1,1],[\"w\\u003c\\u002fw\\u003e\",3,3],[\"tym\\u003c\\u002fw\\u003e\",3,3],[\"zesta\",1,1],[\"wie\\u003c\\u002fw\\u003e\",1,1],[\"nie\\u003c\\u002fw\\u003e\",0,2],[\"warto\\u003c\\u002fw\\u003e\",0,2],[\"nawet\\u003c\\u002fw\\u003e\",0,2],[\"wspominać\\u003c\\u002fw\\u003e\",0,2],[\"Lepiej\\u003c\\u002fw\\u003e\",1,1],[\"od\\u003c\\u002fw\\u003e\",1,3],[\"razu\\u003c\\u002fw\\u003e\",1,1],[\"ja\\u003c\\u002fw\\u003e\",1,3],[\"wyrzucić\\u003c\\u002fw\\u003e\",0,1],[\"Za\\u003c\\u002fw\\u003e\",3,3],[\"połowę\\u003c\\u002fw\\u003e\",1,1],[\"ceny\\u003c\\u002fw\\u003e\",1,1],[\"można\\u003c\\u002fw\\u003e\",1,1],[\"kupić\\u003c\\u002fw\\u003e\",1,1],[\"nieco\\u003c\\u002fw\\u003e\",1,1],[\"lepszy\\u003c\\u002fw\\u003e\",2,2],[\"produkt\\u003c\\u002fw\\u003e\",1,1],[\"produkowany\\u003c\\u002fw\\u003e\",1,1],[\"dla\\u003c\\u002fw\\u003e\",3,3],[\"marke\",1,1],[\"tów\\u003c\\u002fw\\u003e\",1,1],[\"jak\\u003c\\u002fw\\u003e\",3,3],[\"np\\u003c\\u002fw\\u003e\",1,1],[\"Li\",1,1],[\"d\",1,1],[\"l\\u003c\\u002fw\\u003e\",1,1],[\"Jednym\\u003c\\u002fw\\u003e\",1,3],[\"słowem\\u003c\\u002fw\\u003e\",1,1],[\"warto\\u003c\\u002fw\\u003e\",2,1],[\"dołożyć\\u003c\\u002fw\\u003e\",1,1],[\"kilkanaście\\u003c\\u002fw\\u003e\",3,3],[\"złotych\\u003c\\u002fw\\u003e\",1,1],[\"i\\u003c\\u002fw\\u003e\",3,3],[\"zakupić\\u003c\\u002fw\\u003e\",1,1],[\"np\\u003c\\u002fw\\u003e\",1,3],[\"Philip\",1,1],[\"sa\\u003c\\u002fw\\u003e\",1,1],[\"Różnica\\u003c\\u002fw\\u003e\",0,2],[\"kol\",0,2],[\"os\",0,2],[\"alna\\u003c\\u002fw\\u003e\",0,2],[\"Nie\\u003c\\u002fw\\u003e\",0,2],[\"polecam\\u003c\\u002fw\\u003e\",0,2]],\"hovertemplate\":\"Word=%{customdata[0]}\\u003cbr\\u003eLabel=%{customdata[1]}\\u003cbr\\u003ePredicted_label=%{marker.color}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"\",\"marker\":{\"color\":[2,1,3,2,2,1,3,1,1,2,2,2,2,2,3,1,1,1,3,3,1,1,2,2,2,2,1,3,1,3,1,3,1,1,1,1,1,2,1,1,3,1,1,3,1,1,1,1,3,1,1,1,3,1,3,1,3,1,1,2,2,2,2,2,2],\"coloraxis\":\"coloraxis\",\"symbol\":\"circle\"},\"mode\":\"markers\",\"name\":\"\",\"orientation\":\"v\",\"showlegend\":false,\"x\":[6.241216,2.8331761,6.515963,5.913111,6.0981326,5.520756,3.1607218,1.5194434,1.9589006,6.643826,6.4909363,6.608276,6.6454177,6.900935,2.515162,0.9491554,0.9778184,1.1390268,2.8483746,3.0081208,1.5031313,1.6288223,4.6874566,5.295852,5.080602,5.5656962,2.6886294,3.0088937,3.0444145,2.8213713,3.1900737,2.4826162,2.6826863,1.9484801,2.3257864,1.8498307,3.3975675,7.002956,1.978608,2.178629,2.5544102,1.1103346,0.9756745,2.5307539,1.2893474,0.83741486,0.6672268,0.75558054,2.0483997,2.2319806,3.241665,3.2490838,2.897226,2.8066723,2.7222826,1.7731614,2.1068459,1.3799095,1.2529907,6.727795,7.068455,7.1260276,7.0947175,6.909062,6.89318],\"xaxis\":\"x13\",\"y\":[2.999301,4.1296344,2.9883125,2.9508924,2.9931924,3.0912306,-1.4440546,3.8008053,3.7242265,0.5043543,0.4150582,0.37533405,0.24433184,0.44944754,-1.8409863,3.4332216,3.5332096,3.4249797,-1.780702,-1.5369478,3.6983302,3.5986505,0.24146104,0.9396097,0.8241132,0.8736547,2.6713624,-1.7754197,2.4287717,-1.0286624,2.6156878,-1.7899529,2.0991545,2.9097164,1.051604,2.3687007,1.1046547,1.8552629,2.83532,2.0180163,-1.6027501,2.3957937,1.9003378,-1.4693203,0.9679427,2.7510214,2.819473,2.683365,-1.2927886,3.1401954,1.6038971,1.7558863,-0.20879848,0.1899112,-1.7651021,3.075528,-0.7588576,2.8577635,2.8105655,1.1852285,1.3939774,1.562708,1.4753696,1.2406125,1.1613723],\"yaxis\":\"y13\",\"type\":\"scatter\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0]},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.9461538461538461,1.0]},\"xaxis2\":{\"anchor\":\"y2\",\"domain\":[0.0,1.0]},\"yaxis2\":{\"anchor\":\"x2\",\"domain\":[0.8673076923076922,0.9211538461538461]},\"xaxis3\":{\"anchor\":\"y3\",\"domain\":[0.0,1.0]},\"yaxis3\":{\"anchor\":\"x3\",\"domain\":[0.7884615384615383,0.8423076923076922]},\"xaxis4\":{\"anchor\":\"y4\",\"domain\":[0.0,1.0]},\"yaxis4\":{\"anchor\":\"x4\",\"domain\":[0.7096153846153845,0.7634615384615384]},\"xaxis5\":{\"anchor\":\"y5\",\"domain\":[0.0,1.0]},\"yaxis5\":{\"anchor\":\"x5\",\"domain\":[0.6307692307692307,0.6846153846153846]},\"xaxis6\":{\"anchor\":\"y6\",\"domain\":[0.0,1.0]},\"yaxis6\":{\"anchor\":\"x6\",\"domain\":[0.5519230769230768,0.6057692307692307]},\"xaxis7\":{\"anchor\":\"y7\",\"domain\":[0.0,1.0]},\"yaxis7\":{\"anchor\":\"x7\",\"domain\":[0.47307692307692306,0.5269230769230769]},\"xaxis8\":{\"anchor\":\"y8\",\"domain\":[0.0,1.0]},\"yaxis8\":{\"anchor\":\"x8\",\"domain\":[0.3942307692307692,0.44807692307692304]},\"xaxis9\":{\"anchor\":\"y9\",\"domain\":[0.0,1.0]},\"yaxis9\":{\"anchor\":\"x9\",\"domain\":[0.3153846153846154,0.3692307692307692]},\"xaxis10\":{\"anchor\":\"y10\",\"domain\":[0.0,1.0]},\"yaxis10\":{\"anchor\":\"x10\",\"domain\":[0.23653846153846153,0.29038461538461535]},\"xaxis11\":{\"anchor\":\"y11\",\"domain\":[0.0,1.0]},\"yaxis11\":{\"anchor\":\"x11\",\"domain\":[0.1576923076923077,0.21153846153846154]},\"xaxis12\":{\"anchor\":\"y12\",\"domain\":[0.0,1.0]},\"yaxis12\":{\"anchor\":\"x12\",\"domain\":[0.07884615384615384,0.1326923076923077]},\"xaxis13\":{\"anchor\":\"y13\",\"domain\":[0.0,1.0]},\"yaxis13\":{\"anchor\":\"x13\",\"domain\":[0.0,0.05384615384615384]},\"annotations\":[{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\"Layer 1\",\"x\":0.5,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":1.0,\"yanchor\":\"bottom\",\"yref\":\"paper\"},{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\"Layer 2\",\"x\":0.5,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":0.9211538461538461,\"yanchor\":\"bottom\",\"yref\":\"paper\"},{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\"Layer 3\",\"x\":0.5,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":0.8423076923076922,\"yanchor\":\"bottom\",\"yref\":\"paper\"},{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\"Layer 4\",\"x\":0.5,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":0.7634615384615384,\"yanchor\":\"bottom\",\"yref\":\"paper\"},{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\"Layer 5\",\"x\":0.5,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":0.6846153846153846,\"yanchor\":\"bottom\",\"yref\":\"paper\"},{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\"Layer 6\",\"x\":0.5,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":0.6057692307692307,\"yanchor\":\"bottom\",\"yref\":\"paper\"},{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\"Layer 7\",\"x\":0.5,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":0.5269230769230769,\"yanchor\":\"bottom\",\"yref\":\"paper\"},{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\"Layer 8\",\"x\":0.5,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":0.44807692307692304,\"yanchor\":\"bottom\",\"yref\":\"paper\"},{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\"Layer 9\",\"x\":0.5,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":0.3692307692307692,\"yanchor\":\"bottom\",\"yref\":\"paper\"},{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\"Layer 10\",\"x\":0.5,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":0.29038461538461535,\"yanchor\":\"bottom\",\"yref\":\"paper\"},{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\"Layer 11\",\"x\":0.5,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":0.21153846153846154,\"yanchor\":\"bottom\",\"yref\":\"paper\"},{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\"Layer 12\",\"x\":0.5,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":0.1326923076923077,\"yanchor\":\"bottom\",\"yref\":\"paper\"},{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\"Layer 13\",\"x\":0.5,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":0.05384615384615384,\"yanchor\":\"bottom\",\"yref\":\"paper\"}],\"title\":{\"text\":\"t-SNE Embedding Visualization Across Layers with Hover Data\"},\"height\":6500,\"showlegend\":true},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('5621c445-91db-41a5-b708-069a9812b4e1');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.2"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}